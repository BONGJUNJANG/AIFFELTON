{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "559ac99c",
   "metadata": {},
   "source": [
    "# 1D_CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b02c544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pandas_datareader as pdr   \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3714f0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(123)\n",
    "torch.manual_seed(123)\n",
    "torch.cuda.manual_seed(123)               # type: ignore\n",
    "torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "torch.backends.cudnn.benchmark = True      # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be45b22d",
   "metadata": {},
   "source": [
    "## 데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94f9b24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_csv('/home/jbj4278/ETH_data/final_dateadd') #feature포함 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "505b3c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['Date','Open', 'High', 'Low', 'Close', 'Volume','BTC_close', 'DXY', 'BTCD', 'Kimchi_premium', 'S&P500', 'Ethereum DeFi',\n",
    "       'News_freq','signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c64643b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final.loc[:,col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af2ccac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final.loc[final['signal']==0.0 , \"signal\"] = 2   # 보합 > 2로\n",
    "final.loc[final['signal']==1.0 , \"signal\"] = 0  \n",
    " # 상승 > 0으로\n",
    "final.loc[final['signal']==-1.0 , \"signal\"] = 1 #하락 > 1로\n",
    "#(상승, 하락, 보합) > (0 ,1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f67c9942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    188025\n",
       "1.0    171867\n",
       "2.0    163209\n",
       "Name: signal, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final['signal'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63476556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data, label, window_size):\n",
    "    feature_list = []\n",
    "    label_list = []\n",
    "    for i in range(len(data) - window_size):\n",
    "        feature_list.append(np.array(data.iloc[i:i+window_size]))\n",
    "        label_list.append(np.array(label.iloc[i+window_size]))\n",
    "    return np.array(feature_list), np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8e464b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53286fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_test = int(len(final)*0.2)\n",
    "test_set = final[-len_test:]\n",
    "tr_set = final[:-len_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4eef5f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104620, 14)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "692d8709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418481, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2159aeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23388487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgyeongmocho\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\r\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3233cb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import f1_score,precision_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce3c822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    " \n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    \n",
    "    loss_list = []\n",
    "    for idx, (feature, label) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(feature.to(device))\n",
    "        loss = criterion(predicted_label, label.to(device))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        \n",
    "        total_count += label.size(0)\n",
    "        loss_list.append(loss.item())\n",
    "        \n",
    "        if idx+1 % len(feature) == 0 and idx > 0:\n",
    "            accuracy = total_acc/total_count\n",
    "            loss_hist = np.mean(loss_list)\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f'| epoch {epoch} | {idx}/{len(dataloader)} batches '\n",
    "                f'| accuracy {accuracy} | loss {loss_hist}')\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "    wandb.log({'train_loss':np.mean(loss_list),'train_acc':total_acc/total_count})  \n",
    "    return  total_acc/total_count,np.mean(loss_list)\n",
    "    \n",
    "            \n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "    loss_list = []\n",
    "    \n",
    "    score,precision,recall = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (feature, label) in enumerate(dataloader):\n",
    "            feature, label = feature.to(device),label.to(device)\n",
    "            predicted_label = model(feature.to(device))\n",
    "            loss = criterion(predicted_label, label.to(device))\n",
    "            \n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "            loss_list.append(loss.item())\n",
    "            \n",
    "            \n",
    "            \n",
    "            score += f1_score(predicted_label.argmax(1).to(device), label,num_classes=3)\n",
    "            precision += precision_recall(predicted_label.argmax(1).to(device), label, average='macro', num_classes=3)[0]\n",
    "            recall += precision_recall(predicted_label.argmax(1).to(device), label, average='macro', num_classes=3)[1]\n",
    "      \n",
    "        \n",
    "        score = score / len(loss_list)\n",
    "        precision = precision / len(loss_list)\n",
    "        recall = recall / len(loss_list)\n",
    "            \n",
    "    wandb.log({'val_loss':np.mean(loss_list), 'val_acc':total_acc/total_count,'f1_score':score,\n",
    "              'precision':precision,'recall':recall})\n",
    "    \n",
    "    return total_acc/total_count, np.mean(loss_list),score\n",
    "\n",
    "\n",
    "def soft_voting(dataloader):\n",
    "    model.eval()\n",
    "    pred_soft = []\n",
    "    with torch.no_grad():\n",
    "        for idx, (feature, label) in enumerate(dataloader):\n",
    "            feature, label = feature.to(device),label.to(device)\n",
    "            predicted_label = model(feature.to(device))\n",
    "            sm = nn.Softmax(dim=1)\n",
    "            probabilities = sm(predicted_label)\n",
    "            prob_arr = (probabilities.detach().cpu().numpy())[0]\n",
    "            pred_soft.append(prob_arr)\n",
    "            \n",
    "    return pred_soft\n",
    "\n",
    "            \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1901915",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"주어진 patience 이후로 validation loss가 개선되지 않으면 학습을 조기 중지\"\"\"\n",
    "    def __init__(self,path, patience=10, verbose=False, delta=0,):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): validation loss가 개선된 후 기다리는 기간\n",
    "                            Default: 7\n",
    "            verbose (bool): True일 경우 각 validation loss의 개선 사항 메세지 출력\n",
    "                            Default: False\n",
    "            delta (float): 개선되었다고 인정되는 monitered quantity의 최소 변화\n",
    "                            Default: 0\n",
    "            path (str): checkpoint저장 경로\n",
    "                            Default: 'checkpoint.pt'\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        \n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''validation loss가 감소하면 모델을 저장한다.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f457998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockingTimeSeriesSplit():\n",
    "    def __init__(self, n_splits):\n",
    "        self.n_splits = n_splits\n",
    "    \n",
    "    def get_n_splits(self, groups):\n",
    "        return self.n_splits\n",
    "    \n",
    "    def split(self, X, y=None, groups=None):\n",
    "        n_samples = len(X)\n",
    "        k_fold_size = n_samples // self.n_splits\n",
    "        indices = np.arange(n_samples)\n",
    "    \n",
    "        margin = 0\n",
    "        for i in range(self.n_splits):\n",
    "            start = i * k_fold_size\n",
    "            stop = start + k_fold_size\n",
    "            mid = int(0.9 * (stop - start)) + start\n",
    "            yield indices[start: mid], indices[mid + margin: stop]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1777a69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d(nn.Module):\n",
    "    def __init__(self,outchannels, kennel_size, in_channel=12, num_class=3):\n",
    "        super(Conv1d, self).__init__()\n",
    "        self.outchannels = outchannels\n",
    "        self.kennel_size = kennel_size\n",
    "        self.conv1d_1 = nn.Conv1d(in_channels=in_channel,\n",
    "                                out_channels=outchannels,\n",
    "                                kernel_size=kennel_size,\n",
    "                                stride=1)\n",
    "        \n",
    "        \n",
    "                                \n",
    "        self.pool = nn.AdaptiveAvgPool1d(1) #global average pooling\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "        self.dense1 = nn.Linear(outchannels,6)\n",
    "        \n",
    "        self.dense2 = nn.Linear(6,num_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "\t# Raw x shape : (B, S, F) => (B, 10, 12)\n",
    "        \n",
    "        # Shape : (B, F, S) => (B, 12, 10)\n",
    "        x = x.transpose(1, 2)\n",
    "        \n",
    "        # Shape : (B, F, S) == (B, C, S) // C = channel => (B, 12, x)\n",
    "        x = self.conv1d_1(x)\n",
    "        \n",
    "        x = self.relu(x)\n",
    "        \n",
    "        \n",
    "        # Shape : (B, 12, 1)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        \n",
    "        # Shape : (B, 10)\n",
    "        x = self.dense1(x.squeeze(2))\n",
    "        \n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        \n",
    "        # Shape : (10, O) // O = output => (B, 3)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4dbc9cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1d_1 = nn.Conv1d(in_channels=12,\n",
    "                                out_channels=12,\n",
    "                                kernel_size=6,\n",
    "                                stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b79c55f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 5])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,12,10)\n",
    "a = conv1d_1(a)\n",
    "print(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee9de76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "58a6de91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "outchannels =  12\n",
    "kennel_size = 6\n",
    "\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c65a8885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1f1b4csl) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>0.44777</td></tr><tr><td>train_loss</td><td>1.07711</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">1dcnn_2fully</strong>: <a href=\"https://wandb.ai/gyeongmocho/real/runs/1f1b4csl\" target=\"_blank\">https://wandb.ai/gyeongmocho/real/runs/1f1b4csl</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220604_110833-1f1b4csl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1f1b4csl). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jbj4278/wandb/run-20220604_110944-37czp1ub</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/gyeongmocho/real/runs/37czp1ub\" target=\"_blank\">1dcnn_2fully</a></strong> to <a href=\"https://wandb.ai/gyeongmocho/real\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Conv1d(\n",
      "  (conv1d_1): Conv1d(12, 12, kernel_size=(3,), stride=(1,))\n",
      "  (pool): AdaptiveAvgPool1d(output_size=1)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (dense1): Linear(in_features=12, out_features=6, bias=True)\n",
      "  (dense2): Linear(in_features=6, out_features=3, bias=True)\n",
      ")\n",
      "train_feature:torch.Size([75316, 10, 12]),val_feature:torch.Size([8360, 10, 12])\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 1 | time: 1.2605597972869873s | valid accuracy 0.22882775119617224 | valid loss 1.2448030601848254\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (inf --> 1.244803).  Saving model ...\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 2 | time: 1.3163414001464844s | valid accuracy 0.22882775119617224 | valid loss 1.2492643594741821\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 10\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 3 | time: 1.3843400478363037s | valid accuracy 0.22882775119617224 | valid loss 1.25427292693745\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 2 out of 10\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 4 | time: 1.3973290920257568s | valid accuracy 0.22882775119617224 | valid loss 1.259415586789449\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 3 out of 10\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 5 | time: 1.3857085704803467s | valid accuracy 0.22882775119617224 | valid loss 1.2647446430090703\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 4 out of 10\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 6 | time: 1.3987038135528564s | valid accuracy 0.22882775119617224 | valid loss 1.2699848431529421\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 5 out of 10\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 7 | time: 1.3786211013793945s | valid accuracy 0.22882775119617224 | valid loss 1.275375039288492\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 6 out of 10\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 8 | time: 1.7392191886901855s | valid accuracy 0.22882775119617224 | valid loss 1.2806273897488911\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 7 out of 10\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 9 | time: 1.3615667819976807s | valid accuracy 0.22882775119617224 | valid loss 1.2857363061471418\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 8 out of 10\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 10 | time: 1.3834199905395508s | valid accuracy 0.22882775119617224 | valid loss 1.2906118468804793\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 9 out of 10\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 11 | time: 1.3811211585998535s | valid accuracy 0.22882775119617224 | valid loss 1.2955507925062468\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "save score\n",
      "save voting prob\n",
      "-----------------------------------------------------------\n",
      "Fold Finish\n",
      "-----------------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Conv1d(\n",
      "  (conv1d_1): Conv1d(12, 12, kernel_size=(3,), stride=(1,))\n",
      "  (pool): AdaptiveAvgPool1d(output_size=1)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (dense1): Linear(in_features=12, out_features=6, bias=True)\n",
      "  (dense2): Linear(in_features=6, out_features=3, bias=True)\n",
      ")\n",
      "train_feature:torch.Size([75316, 10, 12]),val_feature:torch.Size([8360, 10, 12])\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 1 | time: 1.407759666442871s | valid accuracy 0.4717703349282297 | valid loss 1.073792607495279\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (inf --> 1.073793).  Saving model ...\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 2 | time: 1.4081125259399414s | valid accuracy 0.4717703349282297 | valid loss 1.0743479204900337\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 10\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 3 | time: 1.4215497970581055s | valid accuracy 0.4717703349282297 | valid loss 1.0749440265424324\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 2 out of 10\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 4 | time: 1.374107837677002s | valid accuracy 0.4717703349282297 | valid loss 1.0756258476864209\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 3 out of 10\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 5 | time: 1.3856072425842285s | valid accuracy 0.4717703349282297 | valid loss 1.0763282703630852\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 4 out of 10\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 6 | time: 1.3268978595733643s | valid accuracy 0.4717703349282297 | valid loss 1.07704352610039\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 5 out of 10\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 7 | time: 1.638333797454834s | valid accuracy 0.4717703349282297 | valid loss 1.0778093608942898\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 6 out of 10\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 8 | time: 1.3358638286590576s | valid accuracy 0.4717703349282297 | valid loss 1.0785731619054622\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 7 out of 10\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 9 | time: 1.283174991607666s | valid accuracy 0.4717703349282297 | valid loss 1.0793705257502468\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 8 out of 10\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 10 | time: 1.2660210132598877s | valid accuracy 0.4717703349282297 | valid loss 1.0801662730448174\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 9 out of 10\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 11 | time: 1.2786250114440918s | valid accuracy 0.4717703349282297 | valid loss 1.081009308497111\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "save score\n",
      "save voting prob\n",
      "-----------------------------------------------------------\n",
      "Fold Finish\n",
      "-----------------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Conv1d(\n",
      "  (conv1d_1): Conv1d(12, 12, kernel_size=(3,), stride=(1,))\n",
      "  (pool): AdaptiveAvgPool1d(output_size=1)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (dense1): Linear(in_features=12, out_features=6, bias=True)\n",
      "  (dense2): Linear(in_features=6, out_features=3, bias=True)\n",
      ")\n",
      "train_feature:torch.Size([75316, 10, 12]),val_feature:torch.Size([8360, 10, 12])\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 1 | time: 1.401390790939331s | valid accuracy 0.29485645933014354 | valid loss 1.115814451015357\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (inf --> 1.115814).  Saving model ...\n",
      "0.001\n",
      "Adjusting learning rate of group 0 to 9.9975e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 2 | time: 1.406827688217163s | valid accuracy 0.28086124401913876 | valid loss 1.113332950707638\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.115814 --> 1.113333).  Saving model ...\n",
      "0.0009997532801828658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| end of epoch 3 | time: 1.3853437900543213s | valid accuracy 0.30251196172248807 | valid loss 1.1114451523983118\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.113333 --> 1.111445).  Saving model ...\n",
      "0.0009997532801828658\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 4 | time: 1.410630226135254s | valid accuracy 0.3200956937799043 | valid loss 1.1100967183257595\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.111445 --> 1.110097).  Saving model ...\n",
      "0.0009997532801828658\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 5 | time: 1.3941001892089844s | valid accuracy 0.33026315789473687 | valid loss 1.109230399131775\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.110097 --> 1.109230).  Saving model ...\n",
      "0.0009997532801828658\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 6 | time: 1.3379671573638916s | valid accuracy 0.3303827751196172 | valid loss 1.1087598818721194\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.109230 --> 1.108760).  Saving model ...\n",
      "0.0009997532801828658\n",
      "Adjusting learning rate of group 0 to 9.9901e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 7 | time: 1.6349239349365234s | valid accuracy 0.33026315789473687 | valid loss 1.108581380410628\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.108760 --> 1.108581).  Saving model ...\n",
      "0.0009990133642141358\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 8 | time: 1.3184802532196045s | valid accuracy 0.33050239234449763 | valid loss 1.1086000113776235\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 10\n",
      "0.0009990133642141358\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 9 | time: 1.3069331645965576s | valid accuracy 0.33086124401913874 | valid loss 1.1087447549357559\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 2 out of 10\n",
      "0.0009990133642141358\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 10 | time: 1.3062057495117188s | valid accuracy 0.3311004784688995 | valid loss 1.1090663328315273\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 3 out of 10\n",
      "0.0009990133642141358\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 11 | time: 1.2936155796051025s | valid accuracy 0.3311004784688995 | valid loss 1.1094882759180935\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 4 out of 10\n",
      "0.0009990133642141358\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 12 | time: 1.2691717147827148s | valid accuracy 0.3311004784688995 | valid loss 1.1100454691684607\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 5 out of 10\n",
      "0.0009990133642141358\n",
      "Adjusting learning rate of group 0 to 9.9778e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 13 | time: 1.2678697109222412s | valid accuracy 0.33098086124401915 | valid loss 1.1105852271571304\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 6 out of 10\n",
      "0.00099778098230154\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 14 | time: 1.2716147899627686s | valid accuracy 0.3311004784688995 | valid loss 1.111148846871925\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 7 out of 10\n",
      "0.00099778098230154\n",
      "Adjusting learning rate of group 0 to 9.9606e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 15 | time: 1.2708542346954346s | valid accuracy 0.33098086124401915 | valid loss 1.111690266565843\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 8 out of 10\n",
      "0.000996057350657239\n",
      "Adjusting learning rate of group 0 to 9.9384e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 16 | time: 1.2775583267211914s | valid accuracy 0.3307416267942584 | valid loss 1.1121820915829053\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 9 out of 10\n",
      "0.0009938441702975688\n",
      "Adjusting learning rate of group 0 to 9.9114e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 17 | time: 1.3245642185211182s | valid accuracy 0.3307416267942584 | valid loss 1.1126337286197778\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "save score\n",
      "save voting prob\n",
      "-----------------------------------------------------------\n",
      "Fold Finish\n",
      "-----------------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Conv1d(\n",
      "  (conv1d_1): Conv1d(12, 12, kernel_size=(3,), stride=(1,))\n",
      "  (pool): AdaptiveAvgPool1d(output_size=1)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (dense1): Linear(in_features=12, out_features=6, bias=True)\n",
      "  (dense2): Linear(in_features=6, out_features=3, bias=True)\n",
      ")\n",
      "train_feature:torch.Size([75316, 10, 12]),val_feature:torch.Size([8360, 10, 12])\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 1 | time: 1.6839203834533691s | valid accuracy 0.17954545454545454 | valid loss 1.3522070537913928\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (inf --> 1.352207).  Saving model ...\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 2 | time: 1.4201438426971436s | valid accuracy 0.17954545454545454 | valid loss 1.3083005421089404\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.352207 --> 1.308301).  Saving model ...\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 3 | time: 1.4236092567443848s | valid accuracy 0.17954545454545454 | valid loss 1.2732662721113726\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.308301 --> 1.273266).  Saving model ...\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 4 | time: 1.4139440059661865s | valid accuracy 0.17954545454545454 | valid loss 1.2452282598524382\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.273266 --> 1.245228).  Saving model ...\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 5 | time: 1.411430835723877s | valid accuracy 0.17954545454545454 | valid loss 1.222303199045586\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.245228 --> 1.222303).  Saving model ...\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 6 | time: 1.3899762630462646s | valid accuracy 0.17954545454545454 | valid loss 1.2035762920524136\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.222303 --> 1.203576).  Saving model ...\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 7 | time: 1.4044017791748047s | valid accuracy 0.17954545454545454 | valid loss 1.1882545785470442\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.203576 --> 1.188255).  Saving model ...\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 8 | time: 1.3797216415405273s | valid accuracy 0.17954545454545454 | valid loss 1.1752817432085674\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.188255 --> 1.175282).  Saving model ...\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 9 | time: 1.4055507183074951s | valid accuracy 0.17954545454545454 | valid loss 1.1642440123991533\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.175282 --> 1.164244).  Saving model ...\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 10 | time: 1.4102411270141602s | valid accuracy 0.17954545454545454 | valid loss 1.1547546151912573\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.164244 --> 1.154755).  Saving model ...\n",
      "0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| end of epoch 11 | time: 1.68634033203125s | valid accuracy 0.17954545454545454 | valid loss 1.1465404665831365\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.154755 --> 1.146540).  Saving model ...\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 12 | time: 1.3490262031555176s | valid accuracy 0.17954545454545454 | valid loss 1.1394443584210945\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.146540 --> 1.139444).  Saving model ...\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 13 | time: 1.3224375247955322s | valid accuracy 0.17954545454545454 | valid loss 1.1331624948617183\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.139444 --> 1.133162).  Saving model ...\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 14 | time: 1.3198037147521973s | valid accuracy 0.17954545454545454 | valid loss 1.1275702570423936\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.133162 --> 1.127570).  Saving model ...\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 15 | time: 1.2948262691497803s | valid accuracy 0.18241626794258373 | valid loss 1.122643965663332\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.127570 --> 1.122644).  Saving model ...\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 16 | time: 1.2972943782806396s | valid accuracy 0.22188995215311005 | valid loss 1.1182745839610244\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.122644 --> 1.118275).  Saving model ...\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 17 | time: 1.3074195384979248s | valid accuracy 0.22404306220095693 | valid loss 1.1145375714157566\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.118275 --> 1.114538).  Saving model ...\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 18 | time: 1.2765774726867676s | valid accuracy 0.2465311004784689 | valid loss 1.111176396861221\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.114538 --> 1.111176).  Saving model ...\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 19 | time: 1.2711288928985596s | valid accuracy 0.291866028708134 | valid loss 1.108173876097708\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.111176 --> 1.108174).  Saving model ...\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 20 | time: 1.2608017921447754s | valid accuracy 0.29366028708133973 | valid loss 1.105451023939884\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.108174 --> 1.105451).  Saving model ...\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 21 | time: 1.3075292110443115s | valid accuracy 0.29533492822966506 | valid loss 1.1030192664175322\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.105451 --> 1.103019).  Saving model ...\n",
      "0.001\n",
      "Adjusting learning rate of group 0 to 9.9975e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 22 | time: 1.654888391494751s | valid accuracy 0.2923444976076555 | valid loss 1.100822029691754\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.103019 --> 1.100822).  Saving model ...\n",
      "0.0009997532801828658\n",
      "Adjusting learning rate of group 0 to 9.9901e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 23 | time: 1.3903837203979492s | valid accuracy 0.29318181818181815 | valid loss 1.0989306009177007\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.100822 --> 1.098931).  Saving model ...\n",
      "0.0009990133642141358\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 24 | time: 1.4072473049163818s | valid accuracy 0.3017942583732057 | valid loss 1.097257906740362\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.098931 --> 1.097258).  Saving model ...\n",
      "0.0009990133642141358\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 25 | time: 1.4164071083068848s | valid accuracy 0.3283492822966507 | valid loss 1.0957890315489336\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.097258 --> 1.095789).  Saving model ...\n",
      "0.0009990133642141358\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 26 | time: 1.3978254795074463s | valid accuracy 0.344377990430622 | valid loss 1.094513141747677\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.095789 --> 1.094513).  Saving model ...\n",
      "0.0009990133642141358\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 27 | time: 1.3511223793029785s | valid accuracy 0.3570574162679426 | valid loss 1.0933500203219326\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.094513 --> 1.093350).  Saving model ...\n",
      "0.0009990133642141358\n",
      "Adjusting learning rate of group 0 to 9.9778e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 28 | time: 1.3651008605957031s | valid accuracy 0.3569377990430622 | valid loss 1.092345371390834\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.093350 --> 1.092345).  Saving model ...\n",
      "0.00099778098230154\n",
      "Adjusting learning rate of group 0 to 9.9606e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 29 | time: 1.376211404800415s | valid accuracy 0.35610047846889953 | valid loss 1.091501528566534\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.092345 --> 1.091502).  Saving model ...\n",
      "0.000996057350657239\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 30 | time: 1.4249131679534912s | valid accuracy 0.35789473684210527 | valid loss 1.0907630884286128\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.091502 --> 1.090763).  Saving model ...\n",
      "0.000996057350657239\n",
      "Adjusting learning rate of group 0 to 9.9384e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 31 | time: 1.4211485385894775s | valid accuracy 0.35729665071770333 | valid loss 1.0900937553608057\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.090763 --> 1.090094).  Saving model ...\n",
      "0.0009938441702975688\n",
      "Adjusting learning rate of group 0 to 9.9114e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 32 | time: 1.421769380569458s | valid accuracy 0.35490430622009567 | valid loss 1.0894996921221416\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.090094 --> 1.089500).  Saving model ...\n",
      "0.0009911436253643444\n",
      "Adjusting learning rate of group 0 to 9.8796e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 33 | time: 1.7079026699066162s | valid accuracy 0.35490430622009567 | valid loss 1.0890850713758757\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.089500 --> 1.089085).  Saving model ...\n",
      "0.0009879583809693736\n",
      "Adjusting learning rate of group 0 to 9.8429e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 34 | time: 1.3973960876464844s | valid accuracy 0.3547846889952153 | valid loss 1.0888050866849495\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.089085 --> 1.088805).  Saving model ...\n",
      "0.0009842915805643154\n",
      "Adjusting learning rate of group 0 to 9.8015e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 35 | time: 1.4243578910827637s | valid accuracy 0.35490430622009567 | valid loss 1.0887316501501836\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.088805 --> 1.088732).  Saving model ...\n",
      "0.0009801468428384714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.7553e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 36 | time: 1.3774683475494385s | valid accuracy 0.35454545454545455 | valid loss 1.0887162288029988\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.088732 --> 1.088716).  Saving model ...\n",
      "0.0009755282581475767\n",
      "Adjusting learning rate of group 0 to 9.7044e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 37 | time: 1.4011404514312744s | valid accuracy 0.3541866028708134 | valid loss 1.0887655146194226\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 10\n",
      "0.0009704403844771127\n",
      "Adjusting learning rate of group 0 to 9.6489e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 38 | time: 1.3764634132385254s | valid accuracy 0.3539473684210526 | valid loss 1.0888993360779502\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 2 out of 10\n",
      "0.0009648882429441257\n",
      "Adjusting learning rate of group 0 to 9.5888e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 39 | time: 1.386660099029541s | valid accuracy 0.35382775119617227 | valid loss 1.0891970739220127\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 3 out of 10\n",
      "0.0009588773128419905\n",
      "Adjusting learning rate of group 0 to 9.5241e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 40 | time: 1.3490347862243652s | valid accuracy 0.35382775119617227 | valid loss 1.0896452556956897\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 4 out of 10\n",
      "0.0009524135262330098\n",
      "Adjusting learning rate of group 0 to 9.4550e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 41 | time: 1.3335072994232178s | valid accuracy 0.35382775119617227 | valid loss 1.0901381319219416\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 5 out of 10\n",
      "0.0009455032620941839\n",
      "Adjusting learning rate of group 0 to 9.3815e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 42 | time: 1.2935700416564941s | valid accuracy 0.35382775119617227 | valid loss 1.0908102230592207\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 6 out of 10\n",
      "0.0009381533400219318\n",
      "Adjusting learning rate of group 0 to 9.3037e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 43 | time: 1.2752504348754883s | valid accuracy 0.35382775119617227 | valid loss 1.0915521816773848\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 7 out of 10\n",
      "0.0009303710135019719\n",
      "Adjusting learning rate of group 0 to 9.2216e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 44 | time: 1.5870556831359863s | valid accuracy 0.35382775119617227 | valid loss 1.0924011035399004\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 8 out of 10\n",
      "0.0009221639627510076\n",
      "Adjusting learning rate of group 0 to 9.1354e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 45 | time: 1.2548511028289795s | valid accuracy 0.35382775119617227 | valid loss 1.0933043107841953\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 9 out of 10\n",
      "0.000913540287137281\n",
      "Adjusting learning rate of group 0 to 9.0451e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 46 | time: 1.3235023021697998s | valid accuracy 0.35382775119617227 | valid loss 1.0943404418049436\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "save score\n",
      "save voting prob\n",
      "-----------------------------------------------------------\n",
      "Fold Finish\n",
      "-----------------------------------------------------------\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Conv1d(\n",
      "  (conv1d_1): Conv1d(12, 12, kernel_size=(3,), stride=(1,))\n",
      "  (pool): AdaptiveAvgPool1d(output_size=1)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (dense1): Linear(in_features=12, out_features=6, bias=True)\n",
      "  (dense2): Linear(in_features=6, out_features=3, bias=True)\n",
      ")\n",
      "train_feature:torch.Size([75316, 10, 12]),val_feature:torch.Size([8360, 10, 12])\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 1 | time: 1.4041163921356201s | valid accuracy 0.47811004784688993 | valid loss 1.082469347751502\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (inf --> 1.082469).  Saving model ...\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 2 | time: 1.4144699573516846s | valid accuracy 0.47811004784688993 | valid loss 1.0834168340220596\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 10\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 3 | time: 1.4281558990478516s | valid accuracy 0.47811004784688993 | valid loss 1.0843260324362554\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 2 out of 10\n",
      "0.001\n",
      "Adjusting learning rate of group 0 to 9.9975e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 4 | time: 1.407182216644287s | valid accuracy 0.4779904306220096 | valid loss 1.085189244963906\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 3 out of 10\n",
      "0.0009997532801828658\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 5 | time: 1.3911197185516357s | valid accuracy 0.4855263157894737 | valid loss 1.085990056847081\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 4 out of 10\n",
      "0.0009997532801828658\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 6 | time: 1.3986055850982666s | valid accuracy 0.4917464114832536 | valid loss 1.0866852565245195\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 5 out of 10\n",
      "0.0009997532801828658\n",
      "Adjusting learning rate of group 0 to 9.9901e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 7 | time: 1.4036822319030762s | valid accuracy 0.47811004784688993 | valid loss 1.0873059106595588\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 6 out of 10\n",
      "0.0009990133642141358\n",
      "Adjusting learning rate of group 0 to 9.9778e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 8 | time: 1.7266559600830078s | valid accuracy 0.41495215311004785 | valid loss 1.0879038174947102\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 7 out of 10\n",
      "0.00099778098230154\n",
      "Adjusting learning rate of group 0 to 9.9606e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 9 | time: 1.3886187076568604s | valid accuracy 0.38636363636363635 | valid loss 1.0884329333449856\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 8 out of 10\n",
      "0.000996057350657239\n",
      "Adjusting learning rate of group 0 to 9.9384e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 10 | time: 1.330883264541626s | valid accuracy 0.3716507177033493 | valid loss 1.0889047384262085\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 9 out of 10\n",
      "0.0009938441702975688\n",
      "Adjusting learning rate of group 0 to 9.9114e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 11 | time: 1.318840503692627s | valid accuracy 0.362200956937799 | valid loss 1.0893514770450015\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "save score\n",
      "save voting prob\n",
      "-----------------------------------------------------------\n",
      "Fold Finish\n",
      "-----------------------------------------------------------\n",
      "f1_score:0.3491071552038193\n",
      "accuracy:0.3494736842105263\n"
     ]
    }
   ],
   "source": [
    "btss = BlockingTimeSeriesSplit(n_splits=5)\n",
    "n_epochs = 100\n",
    "scale_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'BTC_close', 'DXY', 'BTCD',\n",
    "       'Kimchi_premium', 'S&P500', 'Ethereum DeFi', 'News_freq']\n",
    "score_list = []\n",
    "accuracy_list = []\n",
    "val_loss_list = []\n",
    "voting_list = []\n",
    "#cross validation\n",
    "\n",
    "wandb.init(project='real', entity='gyeongmoCho',name='1dcnn_2fully')\n",
    "#wandb.watch(model, criterion, log = \"all\" )\n",
    "\n",
    "\n",
    "for idx,(tr_idx, val_idx) in enumerate(btss.split(tr_set)):\n",
    "    \n",
    "    train_data, val_data = tr_set.iloc[tr_idx], tr_set.iloc[val_idx]\n",
    "    \n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_data[scale_cols])#for문을 돌면서 각 train, val을 스케일링ㅇ\n",
    "    train_feature = scaler.transform(train_data[scale_cols])\n",
    "    train_feature = pd.DataFrame(train_feature)                                 \n",
    "    val_feature = scaler.transform(val_data[scale_cols])\n",
    "    val_feature = pd.DataFrame(val_feature)   \n",
    "\n",
    "    \n",
    "    train_feature, train_label = make_dataset(train_feature, train_data['signal'], window_size)\n",
    "    val_feature, val_label = make_dataset(val_feature, val_data['signal'], window_size)\n",
    "\n",
    "    \n",
    "    #모델 선언 \n",
    "    \n",
    "    model = Conv1d(outchannels, kennel_size).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=0,verbose=True)\n",
    "    total_accu = None\n",
    "    \n",
    "\n",
    "    print(model)\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience = 10, verbose = True)\n",
    "\n",
    "\n",
    "\n",
    "    #스케일링된 데이터를 torch Tensor로 변경\n",
    "    val_feature = torch.FloatTensor(val_feature).to(device)\n",
    "    val_label = torch.LongTensor(val_label).to(device)\n",
    "    train_feature = torch.FloatTensor(train_feature).to(device)\n",
    "    train_label  = torch.LongTensor(train_label).to(device)\n",
    "\n",
    "    train_set = TensorDataset(train_feature,train_label)\n",
    "    val_set = TensorDataset(val_feature,val_label)\n",
    "    \n",
    "    #데이터로더 사용\n",
    "    BATCH_SIZE = 256\n",
    "    train_dataloader = DataLoader(train_set , batch_size=BATCH_SIZE,shuffle=False)\n",
    "    valid_dataloader = DataLoader(val_set, batch_size=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "    print(f\"train_feature:{train_feature.shape},val_feature:{val_feature.shape}\" )\n",
    "    \n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        # 현재 learning rate 출력\n",
    "        print(optimizer.param_groups[0]['lr'])\n",
    "        epoch_start_time = time.time()\n",
    "        accu_train, train_loss = train(train_dataloader)\n",
    "        accu_val,val_loss,score = evaluate(valid_dataloader)\n",
    "        if total_accu is not None and total_accu > accu_val:\n",
    "            scheduler.step()\n",
    "        else:\n",
    "            total_accu = accu_val\n",
    "        print('-' * 59)\n",
    "        print(f'| end of epoch {epoch} | time: {time.time()- epoch_start_time}s | '\n",
    "            f'valid accuracy {accu_val} | valid loss {val_loss}'\n",
    "            ) \n",
    "\n",
    "        print('-' * 59)\n",
    "        \n",
    "        early_stopping(val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "    score_list.append(score)\n",
    "    accuracy_list.append(accu_val)\n",
    "    print(\"save score\")\n",
    "    voting_prob = soft_voting(valid_dataloader)\n",
    "    voting_list.append(voting_prob)\n",
    "    print(\"save voting prob\")\n",
    "    \n",
    "    PATH = f\"/home/jbj4278/ETH_data/1dcnn_2fully{idx}.pt\"\n",
    "    torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "\n",
    "\n",
    "                }, PATH)\n",
    "    print('-' * 59)\n",
    "    print('Fold Finish')\n",
    "    print('-' * 59)\n",
    "\n",
    "score_list = list(map(float, score_list))\n",
    "final_f1_score = np.mean(score_list)\n",
    "acc_list = list(map(float, accuracy_list))\n",
    "final_acc = np.mean(acc_list)\n",
    "print(f\"f1_score:{final_f1_score}\")\n",
    "print(f\"accuracy:{final_acc}\")\n",
    "wandb.log({'mean_f1_score':final_f1_score,\"mean_acc\":final_acc})\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af17e924",
   "metadata": {},
   "source": [
    "## f1-score의 fold별 평균이 가장 좋았던 모델로 Test set 성능 측정\n",
    "out_channels = 12,kennel_size = 6 , batch = 256, lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e9e03d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'BTC_close', 'DXY', 'BTCD',\n",
    "       'Kimchi_premium', 'S&P500', 'Ethereum DeFi', 'News_freq']\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(tr_set[scale_cols])#for문을 돌면서 각 train, val을 스케일링\n",
    "tr_feature = scaler.transform(tr_set[scale_cols])\n",
    "tr_feature = pd.DataFrame(tr_feature)                                 \n",
    "test_feature = scaler.transform(test_set[scale_cols])\n",
    "test_feature = pd.DataFrame(test_feature)   \n",
    "\n",
    "\n",
    "test_feature, test_label = make_dataset(test_feature, test_set['signal'], window_size)\n",
    "\n",
    "\n",
    "#스케일링된 데이터를 torch Tensor로 변경\n",
    "test_feature = torch.FloatTensor(test_feature).to(device)\n",
    "test_label  = torch.LongTensor(test_label).to(device)\n",
    "\n",
    "final_test_set = TensorDataset(test_feature,test_label)\n",
    "\n",
    "\n",
    "#데이터로더 사용\n",
    "BATCH_SIZE = 256\n",
    "test_dataloader = DataLoader(final_test_set , batch_size=BATCH_SIZE,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b70dd2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "scale_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'BTC_close', 'DXY', 'BTCD',\n",
    "       'Kimchi_premium', 'S&P500', 'Ethereum DeFi', 'News_freq']\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(tr_set[scale_cols])#for문을 돌면서 각 train, val을 스케일링ㅇ\n",
    "train_feature = scaler.transform(tr_set[scale_cols])\n",
    "train_feature = pd.DataFrame(train_feature)                                 \n",
    " \n",
    "\n",
    "    \n",
    "train_feature, train_label = make_dataset(train_feature, tr_set['signal'], window_size)\n",
    "  \n",
    "\n",
    "train_feature = torch.FloatTensor(train_feature).to(device)\n",
    "train_label  = torch.LongTensor(train_label).to(device)\n",
    "\n",
    "train_set = TensorDataset(train_feature,train_label)\n",
    "\n",
    "\n",
    "#데이터로더 사용\n",
    "BATCH_SIZE = 256\n",
    "final_dataloader = DataLoader(train_set , batch_size=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed91e003",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 저장 경로\n",
    "path = f\"/home/jbj4278/ETH_data/1dcnn_final_model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e60ecdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best parameter\n",
    "#parameters\n",
    "outchannels =  12\n",
    "kennel_size = 6\n",
    "\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2625e5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-03.\n"
     ]
    }
   ],
   "source": [
    "model = Conv1d(outchannels, kennel_size).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=0,verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3011061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    " \n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    \n",
    "    loss_list = []\n",
    "    for idx, (feature, label) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(feature.to(device))\n",
    "        loss = criterion(predicted_label, label.to(device))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        \n",
    "        total_count += label.size(0)\n",
    "        loss_list.append(loss.item())\n",
    "        \n",
    "        if idx+1 % len(feature) == 0 and idx > 0:\n",
    "            accuracy = total_acc/total_count\n",
    "            loss_hist = np.mean(loss_list)\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f'| epoch {epoch} | {idx}/{len(dataloader)} batches '\n",
    "                f'| accuracy {accuracy} | loss {loss_hist}')\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "      \n",
    "    return  total_acc/total_count,np.mean(loss_list)\n",
    "    \n",
    "            \n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "    loss_list = []\n",
    "    pred_label = []\n",
    "    pred_prob = []\n",
    "    score,precision,recall = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (feature, label) in enumerate(dataloader):\n",
    "            feature, label = feature.to(device),label.to(device)\n",
    "            predicted_label = model(feature.to(device))\n",
    "            loss = criterion(predicted_label, label.to(device))\n",
    "            \n",
    "            \n",
    "            sm = nn.Softmax(dim=1)\n",
    "            probabilities = sm(predicted_label)\n",
    "            prob_arr = (probabilities.detach().cpu().numpy())[0]\n",
    "            pred_prob.append(prob_arr)\n",
    "            \n",
    "            \n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "            loss_list.append(loss.item())\n",
    "            pred_label.append(predicted_label.argmax(1))\n",
    "            \n",
    "            \n",
    "            score += f1_score(predicted_label.argmax(1).to(device), label,num_classes=3)\n",
    "            precision += precision_recall(predicted_label.argmax(1).to(device), label, average='macro', num_classes=3)[0]\n",
    "            recall += precision_recall(predicted_label.argmax(1).to(device), label, average='macro', num_classes=3)[1]\n",
    "      \n",
    "        \n",
    "        score = score / len(loss_list)\n",
    "        precision = precision / len(loss_list)\n",
    "        recall = recall / len(loss_list)\n",
    "            \n",
    "    \n",
    "    \n",
    "    return total_acc/total_count, np.mean(loss_list),score,pred_label,pred_prob\n",
    "\n",
    "\n",
    "            \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f81dd744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 1 | time: 8.334758043289185s | valid accuracy 0.32187171398527864 | valid loss 1.1021751418964787\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (inf --> 1.102175).  Saving model ...\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 2 | time: 8.452173233032227s | valid accuracy 0.32993977631201604 | valid loss 1.099953013847976\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.102175 --> 1.099953).  Saving model ...\n",
      "0.001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 3 | time: 8.351358890533447s | valid accuracy 0.3355128572794188 | valid loss 1.0988157411950725\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.099953 --> 1.098816).  Saving model ...\n",
      "0.001\n",
      "Adjusting learning rate of group 0 to 9.9975e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 4 | time: 8.538983583450317s | valid accuracy 0.3321001816269955 | valid loss 1.0981153850159027\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.098816 --> 1.098115).  Saving model ...\n",
      "0.0009997532801828658\n",
      "Adjusting learning rate of group 0 to 9.9901e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 5 | time: 8.56326413154602s | valid accuracy 0.33064716566293856 | valid loss 1.0976182754290424\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.098115 --> 1.097618).  Saving model ...\n",
      "0.0009990133642141358\n",
      "Adjusting learning rate of group 0 to 9.9778e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 6 | time: 8.754782915115356s | valid accuracy 0.33349584169773444 | valid loss 1.0972118322307147\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.097618 --> 1.097212).  Saving model ...\n",
      "0.00099778098230154\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 7 | time: 8.519559621810913s | valid accuracy 0.3370136698212408 | valid loss 1.0968358509406484\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.097212 --> 1.096836).  Saving model ...\n",
      "0.00099778098230154\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 8 | time: 8.319839239120483s | valid accuracy 0.3442978682726317 | valid loss 1.0964639248066834\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.096836 --> 1.096464).  Saving model ...\n",
      "0.00099778098230154\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 9 | time: 8.328366994857788s | valid accuracy 0.35188796482171875 | valid loss 1.0960774637376183\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.096464 --> 1.096077).  Saving model ...\n",
      "0.00099778098230154\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 10 | time: 8.360619068145752s | valid accuracy 0.353732912723449 | valid loss 1.0956607395395965\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.096077 --> 1.095661).  Saving model ...\n",
      "0.00099778098230154\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 11 | time: 8.341360330581665s | valid accuracy 0.3543829461810534 | valid loss 1.095283178362112\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.095661 --> 1.095283).  Saving model ...\n",
      "0.00099778098230154\n",
      "Adjusting learning rate of group 0 to 9.9606e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 12 | time: 8.403094291687012s | valid accuracy 0.3541439632922283 | valid loss 1.0948640909637974\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.095283 --> 1.094864).  Saving model ...\n",
      "0.000996057350657239\n",
      "Adjusting learning rate of group 0 to 9.9384e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 13 | time: 8.565791606903076s | valid accuracy 0.35381894656342605 | valid loss 1.094476219931558\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.094864 --> 1.094476).  Saving model ...\n",
      "0.0009938441702975688\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 14 | time: 8.759740352630615s | valid accuracy 0.35441162412771243 | valid loss 1.0940896781266174\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.094476 --> 1.094090).  Saving model ...\n",
      "0.0009938441702975688\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 15 | time: 8.752164363861084s | valid accuracy 0.35520504731861197 | valid loss 1.0937636178396732\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.094090 --> 1.093764).  Saving model ...\n",
      "0.0009938441702975688\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 16 | time: 8.690698623657227s | valid accuracy 0.35532931842080107 | valid loss 1.0935098142670536\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.093764 --> 1.093510).  Saving model ...\n",
      "0.0009938441702975688\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 17 | time: 8.432931900024414s | valid accuracy 0.3563330465538667 | valid loss 1.0932263797536164\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.093510 --> 1.093226).  Saving model ...\n",
      "0.0009938441702975688\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 18 | time: 8.291692972183228s | valid accuracy 0.3570213172736832 | valid loss 1.0930182980441814\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.093226 --> 1.093018).  Saving model ...\n",
      "0.0009938441702975688\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 19 | time: 8.635785579681396s | valid accuracy 0.35770002867794665 | valid loss 1.092854224819426\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.093018 --> 1.092854).  Saving model ...\n",
      "0.0009938441702975688\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 20 | time: 8.6100172996521s | valid accuracy 0.35833094350444505 | valid loss 1.092728676597763\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.092854 --> 1.092729).  Saving model ...\n",
      "0.0009938441702975688\n",
      "Adjusting learning rate of group 0 to 9.9114e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 21 | time: 8.3009774684906s | valid accuracy 0.358264028295574 | valid loss 1.0926653056389546\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.092729 --> 1.092665).  Saving model ...\n",
      "0.0009911436253643444\n",
      "Adjusting learning rate of group 0 to 9.8796e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 22 | time: 8.568183898925781s | valid accuracy 0.3580250454067489 | valid loss 1.0926708262823612\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 3\n",
      "0.0009879583809693736\n",
      "Adjusting learning rate of group 0 to 9.8429e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 23 | time: 8.499022483825684s | valid accuracy 0.3566102667049039 | valid loss 1.092812388479564\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 2 out of 3\n",
      "0.0009842915805643154\n",
      "Adjusting learning rate of group 0 to 9.8015e-04.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 24 | time: 8.887084245681763s | valid accuracy 0.35622789408278366 | valid loss 1.0929105746716916\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "tensor(0.3564, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "early_stopping = EarlyStopping(path,patience = 3, verbose = True)\n",
    "\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    # 현재 learning rate 출력\n",
    "    print(optimizer.param_groups[0]['lr'])\n",
    "    epoch_start_time = time.time()\n",
    "    accu_train, train_loss = train(final_dataloader)\n",
    "    accu_test,test_loss,score,label,prob = evaluate(test_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_test:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        total_accu = accu_test\n",
    "    print('-' * 59)\n",
    "    print(f'| end of epoch {epoch} | time: {time.time()- epoch_start_time}s | '\n",
    "        f'valid accuracy {accu_test} | valid loss {test_loss}'\n",
    "        ) \n",
    "\n",
    "    print('-' * 59)\n",
    "\n",
    "    early_stopping(test_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "print(score)\n",
    "torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "\n",
    "\n",
    "                }, path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29ecb78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgyeongmocho\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jbj4278/wandb/run-20220607_083600-oes0tcxv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/gyeongmocho/result/runs/oes0tcxv\" target=\"_blank\">1DCNN</a></strong> to <a href=\"https://wandb.ai/gyeongmocho/result\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project='result', entity='gyeongmoCho',name='1DCNN')\n",
    "wandb.log({'final_f1_score':score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d47e99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = list(map(list, label))\n",
    "\n",
    "answer = sum(pred_label, [])\n",
    "\n",
    "final_label = []\n",
    "for i in answer:\n",
    "    final_label.append(i.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e143bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_result(model,test_dataloader):\n",
    "    model.eval()\n",
    "    pred_soft = []\n",
    "    pred_hard=[]\n",
    "    \n",
    "    correct_count, all_count = 0,0\n",
    "    with torch.no_grad():\n",
    "        for idx, (feature, label) in enumerate(test_dataloader):\n",
    "            if torch.cuda.is_available():\n",
    "                feature, labels = feature.to(device),label.to(device)\n",
    "            for i in range(len(labels)):\n",
    "                #soft\n",
    "                predicted_label = model(feature.to(device))\n",
    "                sm = nn.Softmax(dim=1)\n",
    "                probabilities = sm(predicted_label)\n",
    "                prob_arr = (probabilities.detach().cpu().numpy())[0]\n",
    "                pred_soft.append(prob_arr)\n",
    "                #hard\n",
    "                logps = model(feature.to(device))\n",
    "                ps = torch.exp(logps)\n",
    "                probab = list(ps.cpu()[0])\n",
    "                pred_label = probab.index(max(probab))\n",
    "                true_label = labels.cpu()[i]\n",
    "                pred_hard.append(pred_label)\n",
    "                if(true_label == pred_label):\n",
    "                    correct_count += 1\n",
    "                all_count += 1\n",
    "                \n",
    "                \n",
    "    return pred_soft ,pred_hard\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82e98b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "soft, hard = make_result(model,test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "45a63daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "soft = pd.DataFrame(soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "016a2232",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_labels = pd.DataFrame(final_label,columns = ['pred_labels'])\n",
    "\n",
    "test_set = test_set[:-10]\n",
    "\n",
    "index = final_labels.index\n",
    "\n",
    "test_set.index = index\n",
    "\n",
    "plus_label_df = test_set.join(final_labels['pred_labels'],how='right') \n",
    "\n",
    "plus_label_df = plus_label_df.join(soft,how='right') \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e92b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "plus_label_df.to_csv('final_1DCNN_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f70988a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    84626\n",
       "1    11720\n",
       "0     8264\n",
       "Name: pred_labels, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plus_label_df['pred_labels'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a972c95a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
