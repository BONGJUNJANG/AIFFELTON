{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2f988fa",
   "metadata": {},
   "source": [
    "# LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a55d8f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pandas_datareader as pdr   \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e3636d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import torch\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(123)\n",
    "torch.manual_seed(123)\n",
    "torch.cuda.manual_seed(123)               # type: ignore\n",
    "torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "torch.backends.cudnn.benchmark = True      # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb50c05",
   "metadata": {},
   "source": [
    "## 1. 데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cec1399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final2 = pd.read_csv('/home/jbj4278/ETH_data/final_dateadd') #feature포함 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be0169c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['Date','Open', 'High', 'Low', 'Close', 'Volume','BTC_close', 'DXY', 'BTCD', 'Kimchi_premium', 'S&P500', 'Ethereum DeFi',\n",
    "   'News_freq','signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a84d6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final2.loc[:,col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2be794d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>BTC_close</th>\n",
       "      <th>DXY</th>\n",
       "      <th>BTCD</th>\n",
       "      <th>Kimchi_premium</th>\n",
       "      <th>S&amp;P500</th>\n",
       "      <th>Ethereum DeFi</th>\n",
       "      <th>News_freq</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-23 22:09:00</td>\n",
       "      <td>2019000</td>\n",
       "      <td>2020000</td>\n",
       "      <td>2017000</td>\n",
       "      <td>2018000</td>\n",
       "      <td>101.666675</td>\n",
       "      <td>65987000.0</td>\n",
       "      <td>92.350</td>\n",
       "      <td>61.201411</td>\n",
       "      <td>10.897713</td>\n",
       "      <td>3910.51</td>\n",
       "      <td>4.492662e+10</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-23 22:10:00</td>\n",
       "      <td>2018000</td>\n",
       "      <td>2019000</td>\n",
       "      <td>2017000</td>\n",
       "      <td>2019000</td>\n",
       "      <td>20.106467</td>\n",
       "      <td>65985000.0</td>\n",
       "      <td>92.350</td>\n",
       "      <td>61.201411</td>\n",
       "      <td>10.897713</td>\n",
       "      <td>3910.51</td>\n",
       "      <td>4.492662e+10</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-23 22:11:00</td>\n",
       "      <td>2019000</td>\n",
       "      <td>2020000</td>\n",
       "      <td>2017000</td>\n",
       "      <td>2019000</td>\n",
       "      <td>17.313993</td>\n",
       "      <td>66057000.0</td>\n",
       "      <td>92.350</td>\n",
       "      <td>61.201411</td>\n",
       "      <td>10.897713</td>\n",
       "      <td>3910.51</td>\n",
       "      <td>4.492662e+10</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-23 22:12:00</td>\n",
       "      <td>2020000</td>\n",
       "      <td>2020000</td>\n",
       "      <td>2019000</td>\n",
       "      <td>2019000</td>\n",
       "      <td>36.582210</td>\n",
       "      <td>66012000.0</td>\n",
       "      <td>92.350</td>\n",
       "      <td>61.201411</td>\n",
       "      <td>10.897713</td>\n",
       "      <td>3910.51</td>\n",
       "      <td>4.492662e+10</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-23 22:13:00</td>\n",
       "      <td>2020000</td>\n",
       "      <td>2020000</td>\n",
       "      <td>2016000</td>\n",
       "      <td>2016000</td>\n",
       "      <td>63.727452</td>\n",
       "      <td>66015000.0</td>\n",
       "      <td>92.350</td>\n",
       "      <td>61.201411</td>\n",
       "      <td>10.897713</td>\n",
       "      <td>3910.51</td>\n",
       "      <td>4.492662e+10</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523096</th>\n",
       "      <td>2022-03-23 15:15:00</td>\n",
       "      <td>3666000</td>\n",
       "      <td>3667000</td>\n",
       "      <td>3665000</td>\n",
       "      <td>3665000</td>\n",
       "      <td>39.688187</td>\n",
       "      <td>51801000.0</td>\n",
       "      <td>98.793</td>\n",
       "      <td>42.584513</td>\n",
       "      <td>15.249800</td>\n",
       "      <td>4488.22</td>\n",
       "      <td>1.159212e+11</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523097</th>\n",
       "      <td>2022-03-23 15:16:00</td>\n",
       "      <td>3666000</td>\n",
       "      <td>3669000</td>\n",
       "      <td>3665000</td>\n",
       "      <td>3668000</td>\n",
       "      <td>76.731647</td>\n",
       "      <td>51753000.0</td>\n",
       "      <td>98.793</td>\n",
       "      <td>42.584513</td>\n",
       "      <td>15.249800</td>\n",
       "      <td>4488.22</td>\n",
       "      <td>1.159212e+11</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523098</th>\n",
       "      <td>2022-03-23 15:17:00</td>\n",
       "      <td>3668000</td>\n",
       "      <td>3671000</td>\n",
       "      <td>3667000</td>\n",
       "      <td>3669000</td>\n",
       "      <td>96.039465</td>\n",
       "      <td>51782000.0</td>\n",
       "      <td>98.793</td>\n",
       "      <td>42.584513</td>\n",
       "      <td>15.249800</td>\n",
       "      <td>4488.22</td>\n",
       "      <td>1.159212e+11</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523099</th>\n",
       "      <td>2022-03-23 15:18:00</td>\n",
       "      <td>3667000</td>\n",
       "      <td>3674000</td>\n",
       "      <td>3663000</td>\n",
       "      <td>3663000</td>\n",
       "      <td>91.949217</td>\n",
       "      <td>51780000.0</td>\n",
       "      <td>98.793</td>\n",
       "      <td>42.584513</td>\n",
       "      <td>15.249800</td>\n",
       "      <td>4488.22</td>\n",
       "      <td>1.159212e+11</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523100</th>\n",
       "      <td>2022-03-23 15:19:00</td>\n",
       "      <td>3663000</td>\n",
       "      <td>3663000</td>\n",
       "      <td>3660000</td>\n",
       "      <td>3662000</td>\n",
       "      <td>29.505753</td>\n",
       "      <td>51728000.0</td>\n",
       "      <td>98.793</td>\n",
       "      <td>42.584513</td>\n",
       "      <td>15.249800</td>\n",
       "      <td>4488.22</td>\n",
       "      <td>1.159212e+11</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>523101 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date     Open     High      Low    Close      Volume  \\\n",
       "0       2021-03-23 22:09:00  2019000  2020000  2017000  2018000  101.666675   \n",
       "1       2021-03-23 22:10:00  2018000  2019000  2017000  2019000   20.106467   \n",
       "2       2021-03-23 22:11:00  2019000  2020000  2017000  2019000   17.313993   \n",
       "3       2021-03-23 22:12:00  2020000  2020000  2019000  2019000   36.582210   \n",
       "4       2021-03-23 22:13:00  2020000  2020000  2016000  2016000   63.727452   \n",
       "...                     ...      ...      ...      ...      ...         ...   \n",
       "523096  2022-03-23 15:15:00  3666000  3667000  3665000  3665000   39.688187   \n",
       "523097  2022-03-23 15:16:00  3666000  3669000  3665000  3668000   76.731647   \n",
       "523098  2022-03-23 15:17:00  3668000  3671000  3667000  3669000   96.039465   \n",
       "523099  2022-03-23 15:18:00  3667000  3674000  3663000  3663000   91.949217   \n",
       "523100  2022-03-23 15:19:00  3663000  3663000  3660000  3662000   29.505753   \n",
       "\n",
       "         BTC_close     DXY       BTCD  Kimchi_premium   S&P500  Ethereum DeFi  \\\n",
       "0       65987000.0  92.350  61.201411       10.897713  3910.51   4.492662e+10   \n",
       "1       65985000.0  92.350  61.201411       10.897713  3910.51   4.492662e+10   \n",
       "2       66057000.0  92.350  61.201411       10.897713  3910.51   4.492662e+10   \n",
       "3       66012000.0  92.350  61.201411       10.897713  3910.51   4.492662e+10   \n",
       "4       66015000.0  92.350  61.201411       10.897713  3910.51   4.492662e+10   \n",
       "...            ...     ...        ...             ...      ...            ...   \n",
       "523096  51801000.0  98.793  42.584513       15.249800  4488.22   1.159212e+11   \n",
       "523097  51753000.0  98.793  42.584513       15.249800  4488.22   1.159212e+11   \n",
       "523098  51782000.0  98.793  42.584513       15.249800  4488.22   1.159212e+11   \n",
       "523099  51780000.0  98.793  42.584513       15.249800  4488.22   1.159212e+11   \n",
       "523100  51728000.0  98.793  42.584513       15.249800  4488.22   1.159212e+11   \n",
       "\n",
       "        News_freq  signal  \n",
       "0           142.0     0.0  \n",
       "1           142.0     0.0  \n",
       "2           142.0     0.0  \n",
       "3           142.0     0.0  \n",
       "4           142.0     0.0  \n",
       "...           ...     ...  \n",
       "523096       57.0     0.0  \n",
       "523097       57.0     0.0  \n",
       "523098       57.0     0.0  \n",
       "523099       57.0     0.0  \n",
       "523100       57.0     0.0  \n",
       "\n",
       "[523101 rows x 14 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eaccf575",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final.loc[final['signal']==0.0 , \"signal\"] = 2   # 보합 > 2로\n",
    "final.loc[final['signal']==1.0 , \"signal\"] = 0  \n",
    " # 상승 > 0으로\n",
    "final.loc[final['signal']==-1.0 , \"signal\"] = 1 #하락 > 1로\n",
    "#(상승, 하락, 보합) > (0 ,1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a353287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    188025\n",
       "1.0    171867\n",
       "2.0    163209\n",
       "Name: signal, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final['signal'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18ee03a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>BTC_close</th>\n",
       "      <th>DXY</th>\n",
       "      <th>BTCD</th>\n",
       "      <th>Kimchi_premium</th>\n",
       "      <th>S&amp;P500</th>\n",
       "      <th>Ethereum DeFi</th>\n",
       "      <th>News_freq</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-23 22:09:00</td>\n",
       "      <td>2019000</td>\n",
       "      <td>2020000</td>\n",
       "      <td>2017000</td>\n",
       "      <td>2018000</td>\n",
       "      <td>101.666675</td>\n",
       "      <td>65987000.0</td>\n",
       "      <td>92.350</td>\n",
       "      <td>61.201411</td>\n",
       "      <td>10.897713</td>\n",
       "      <td>3910.51</td>\n",
       "      <td>4.492662e+10</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-23 22:10:00</td>\n",
       "      <td>2018000</td>\n",
       "      <td>2019000</td>\n",
       "      <td>2017000</td>\n",
       "      <td>2019000</td>\n",
       "      <td>20.106467</td>\n",
       "      <td>65985000.0</td>\n",
       "      <td>92.350</td>\n",
       "      <td>61.201411</td>\n",
       "      <td>10.897713</td>\n",
       "      <td>3910.51</td>\n",
       "      <td>4.492662e+10</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-23 22:11:00</td>\n",
       "      <td>2019000</td>\n",
       "      <td>2020000</td>\n",
       "      <td>2017000</td>\n",
       "      <td>2019000</td>\n",
       "      <td>17.313993</td>\n",
       "      <td>66057000.0</td>\n",
       "      <td>92.350</td>\n",
       "      <td>61.201411</td>\n",
       "      <td>10.897713</td>\n",
       "      <td>3910.51</td>\n",
       "      <td>4.492662e+10</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-23 22:12:00</td>\n",
       "      <td>2020000</td>\n",
       "      <td>2020000</td>\n",
       "      <td>2019000</td>\n",
       "      <td>2019000</td>\n",
       "      <td>36.582210</td>\n",
       "      <td>66012000.0</td>\n",
       "      <td>92.350</td>\n",
       "      <td>61.201411</td>\n",
       "      <td>10.897713</td>\n",
       "      <td>3910.51</td>\n",
       "      <td>4.492662e+10</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-23 22:13:00</td>\n",
       "      <td>2020000</td>\n",
       "      <td>2020000</td>\n",
       "      <td>2016000</td>\n",
       "      <td>2016000</td>\n",
       "      <td>63.727452</td>\n",
       "      <td>66015000.0</td>\n",
       "      <td>92.350</td>\n",
       "      <td>61.201411</td>\n",
       "      <td>10.897713</td>\n",
       "      <td>3910.51</td>\n",
       "      <td>4.492662e+10</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523096</th>\n",
       "      <td>2022-03-23 15:15:00</td>\n",
       "      <td>3666000</td>\n",
       "      <td>3667000</td>\n",
       "      <td>3665000</td>\n",
       "      <td>3665000</td>\n",
       "      <td>39.688187</td>\n",
       "      <td>51801000.0</td>\n",
       "      <td>98.793</td>\n",
       "      <td>42.584513</td>\n",
       "      <td>15.249800</td>\n",
       "      <td>4488.22</td>\n",
       "      <td>1.159212e+11</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523097</th>\n",
       "      <td>2022-03-23 15:16:00</td>\n",
       "      <td>3666000</td>\n",
       "      <td>3669000</td>\n",
       "      <td>3665000</td>\n",
       "      <td>3668000</td>\n",
       "      <td>76.731647</td>\n",
       "      <td>51753000.0</td>\n",
       "      <td>98.793</td>\n",
       "      <td>42.584513</td>\n",
       "      <td>15.249800</td>\n",
       "      <td>4488.22</td>\n",
       "      <td>1.159212e+11</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523098</th>\n",
       "      <td>2022-03-23 15:17:00</td>\n",
       "      <td>3668000</td>\n",
       "      <td>3671000</td>\n",
       "      <td>3667000</td>\n",
       "      <td>3669000</td>\n",
       "      <td>96.039465</td>\n",
       "      <td>51782000.0</td>\n",
       "      <td>98.793</td>\n",
       "      <td>42.584513</td>\n",
       "      <td>15.249800</td>\n",
       "      <td>4488.22</td>\n",
       "      <td>1.159212e+11</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523099</th>\n",
       "      <td>2022-03-23 15:18:00</td>\n",
       "      <td>3667000</td>\n",
       "      <td>3674000</td>\n",
       "      <td>3663000</td>\n",
       "      <td>3663000</td>\n",
       "      <td>91.949217</td>\n",
       "      <td>51780000.0</td>\n",
       "      <td>98.793</td>\n",
       "      <td>42.584513</td>\n",
       "      <td>15.249800</td>\n",
       "      <td>4488.22</td>\n",
       "      <td>1.159212e+11</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523100</th>\n",
       "      <td>2022-03-23 15:19:00</td>\n",
       "      <td>3663000</td>\n",
       "      <td>3663000</td>\n",
       "      <td>3660000</td>\n",
       "      <td>3662000</td>\n",
       "      <td>29.505753</td>\n",
       "      <td>51728000.0</td>\n",
       "      <td>98.793</td>\n",
       "      <td>42.584513</td>\n",
       "      <td>15.249800</td>\n",
       "      <td>4488.22</td>\n",
       "      <td>1.159212e+11</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>523101 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date     Open     High      Low    Close      Volume  \\\n",
       "0       2021-03-23 22:09:00  2019000  2020000  2017000  2018000  101.666675   \n",
       "1       2021-03-23 22:10:00  2018000  2019000  2017000  2019000   20.106467   \n",
       "2       2021-03-23 22:11:00  2019000  2020000  2017000  2019000   17.313993   \n",
       "3       2021-03-23 22:12:00  2020000  2020000  2019000  2019000   36.582210   \n",
       "4       2021-03-23 22:13:00  2020000  2020000  2016000  2016000   63.727452   \n",
       "...                     ...      ...      ...      ...      ...         ...   \n",
       "523096  2022-03-23 15:15:00  3666000  3667000  3665000  3665000   39.688187   \n",
       "523097  2022-03-23 15:16:00  3666000  3669000  3665000  3668000   76.731647   \n",
       "523098  2022-03-23 15:17:00  3668000  3671000  3667000  3669000   96.039465   \n",
       "523099  2022-03-23 15:18:00  3667000  3674000  3663000  3663000   91.949217   \n",
       "523100  2022-03-23 15:19:00  3663000  3663000  3660000  3662000   29.505753   \n",
       "\n",
       "         BTC_close     DXY       BTCD  Kimchi_premium   S&P500  Ethereum DeFi  \\\n",
       "0       65987000.0  92.350  61.201411       10.897713  3910.51   4.492662e+10   \n",
       "1       65985000.0  92.350  61.201411       10.897713  3910.51   4.492662e+10   \n",
       "2       66057000.0  92.350  61.201411       10.897713  3910.51   4.492662e+10   \n",
       "3       66012000.0  92.350  61.201411       10.897713  3910.51   4.492662e+10   \n",
       "4       66015000.0  92.350  61.201411       10.897713  3910.51   4.492662e+10   \n",
       "...            ...     ...        ...             ...      ...            ...   \n",
       "523096  51801000.0  98.793  42.584513       15.249800  4488.22   1.159212e+11   \n",
       "523097  51753000.0  98.793  42.584513       15.249800  4488.22   1.159212e+11   \n",
       "523098  51782000.0  98.793  42.584513       15.249800  4488.22   1.159212e+11   \n",
       "523099  51780000.0  98.793  42.584513       15.249800  4488.22   1.159212e+11   \n",
       "523100  51728000.0  98.793  42.584513       15.249800  4488.22   1.159212e+11   \n",
       "\n",
       "        News_freq  signal  \n",
       "0           142.0     2.0  \n",
       "1           142.0     2.0  \n",
       "2           142.0     2.0  \n",
       "3           142.0     2.0  \n",
       "4           142.0     2.0  \n",
       "...           ...     ...  \n",
       "523096       57.0     2.0  \n",
       "523097       57.0     2.0  \n",
       "523098       57.0     2.0  \n",
       "523099       57.0     2.0  \n",
       "523100       57.0     2.0  \n",
       "\n",
       "[523101 rows x 14 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ab03901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data, label, window_size):\n",
    "    feature_list = []\n",
    "    label_list = []\n",
    "    for i in range(len(data) - window_size):\n",
    "        feature_list.append(np.array(data.iloc[i:i+window_size]))\n",
    "        label_list.append(np.array(label.iloc[i+window_size]))\n",
    "    return np.array(feature_list), np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7f9e0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cc6cae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(523101, 14)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eaad77b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_test = int(len(final)*0.2)\n",
    "test_set = final[-len_test:]\n",
    "tr_set = final[:-len_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f92b7925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104620, 14)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8415a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>BTC_close</th>\n",
       "      <th>DXY</th>\n",
       "      <th>BTCD</th>\n",
       "      <th>Kimchi_premium</th>\n",
       "      <th>S&amp;P500</th>\n",
       "      <th>Ethereum DeFi</th>\n",
       "      <th>News_freq</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>418481</th>\n",
       "      <td>2022-01-09 20:55:00</td>\n",
       "      <td>3934000</td>\n",
       "      <td>3934000</td>\n",
       "      <td>3931000</td>\n",
       "      <td>3933000</td>\n",
       "      <td>7.091395</td>\n",
       "      <td>52343000.0</td>\n",
       "      <td>95.739</td>\n",
       "      <td>40.435605</td>\n",
       "      <td>-12.94548</td>\n",
       "      <td>4677.04</td>\n",
       "      <td>1.401528e+11</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418482</th>\n",
       "      <td>2022-01-09 20:56:00</td>\n",
       "      <td>3933000</td>\n",
       "      <td>3935000</td>\n",
       "      <td>3931000</td>\n",
       "      <td>3932000</td>\n",
       "      <td>14.144101</td>\n",
       "      <td>52315000.0</td>\n",
       "      <td>95.739</td>\n",
       "      <td>40.435605</td>\n",
       "      <td>-12.94548</td>\n",
       "      <td>4677.04</td>\n",
       "      <td>1.401528e+11</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418483</th>\n",
       "      <td>2022-01-09 20:57:00</td>\n",
       "      <td>3932000</td>\n",
       "      <td>3934000</td>\n",
       "      <td>3930000</td>\n",
       "      <td>3933000</td>\n",
       "      <td>19.051929</td>\n",
       "      <td>52313000.0</td>\n",
       "      <td>95.739</td>\n",
       "      <td>40.435605</td>\n",
       "      <td>-12.94548</td>\n",
       "      <td>4677.04</td>\n",
       "      <td>1.401528e+11</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418484</th>\n",
       "      <td>2022-01-09 20:58:00</td>\n",
       "      <td>3933000</td>\n",
       "      <td>3935000</td>\n",
       "      <td>3930000</td>\n",
       "      <td>3935000</td>\n",
       "      <td>11.908381</td>\n",
       "      <td>52313000.0</td>\n",
       "      <td>95.739</td>\n",
       "      <td>40.435605</td>\n",
       "      <td>-12.94548</td>\n",
       "      <td>4677.04</td>\n",
       "      <td>1.401528e+11</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418485</th>\n",
       "      <td>2022-01-09 20:59:00</td>\n",
       "      <td>3935000</td>\n",
       "      <td>3936000</td>\n",
       "      <td>3934000</td>\n",
       "      <td>3935000</td>\n",
       "      <td>7.690722</td>\n",
       "      <td>52292000.0</td>\n",
       "      <td>95.739</td>\n",
       "      <td>40.435605</td>\n",
       "      <td>-12.94548</td>\n",
       "      <td>4677.04</td>\n",
       "      <td>1.401528e+11</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523096</th>\n",
       "      <td>2022-03-23 15:15:00</td>\n",
       "      <td>3666000</td>\n",
       "      <td>3667000</td>\n",
       "      <td>3665000</td>\n",
       "      <td>3665000</td>\n",
       "      <td>39.688187</td>\n",
       "      <td>51801000.0</td>\n",
       "      <td>98.793</td>\n",
       "      <td>42.584513</td>\n",
       "      <td>15.24980</td>\n",
       "      <td>4488.22</td>\n",
       "      <td>1.159212e+11</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523097</th>\n",
       "      <td>2022-03-23 15:16:00</td>\n",
       "      <td>3666000</td>\n",
       "      <td>3669000</td>\n",
       "      <td>3665000</td>\n",
       "      <td>3668000</td>\n",
       "      <td>76.731647</td>\n",
       "      <td>51753000.0</td>\n",
       "      <td>98.793</td>\n",
       "      <td>42.584513</td>\n",
       "      <td>15.24980</td>\n",
       "      <td>4488.22</td>\n",
       "      <td>1.159212e+11</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523098</th>\n",
       "      <td>2022-03-23 15:17:00</td>\n",
       "      <td>3668000</td>\n",
       "      <td>3671000</td>\n",
       "      <td>3667000</td>\n",
       "      <td>3669000</td>\n",
       "      <td>96.039465</td>\n",
       "      <td>51782000.0</td>\n",
       "      <td>98.793</td>\n",
       "      <td>42.584513</td>\n",
       "      <td>15.24980</td>\n",
       "      <td>4488.22</td>\n",
       "      <td>1.159212e+11</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523099</th>\n",
       "      <td>2022-03-23 15:18:00</td>\n",
       "      <td>3667000</td>\n",
       "      <td>3674000</td>\n",
       "      <td>3663000</td>\n",
       "      <td>3663000</td>\n",
       "      <td>91.949217</td>\n",
       "      <td>51780000.0</td>\n",
       "      <td>98.793</td>\n",
       "      <td>42.584513</td>\n",
       "      <td>15.24980</td>\n",
       "      <td>4488.22</td>\n",
       "      <td>1.159212e+11</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523100</th>\n",
       "      <td>2022-03-23 15:19:00</td>\n",
       "      <td>3663000</td>\n",
       "      <td>3663000</td>\n",
       "      <td>3660000</td>\n",
       "      <td>3662000</td>\n",
       "      <td>29.505753</td>\n",
       "      <td>51728000.0</td>\n",
       "      <td>98.793</td>\n",
       "      <td>42.584513</td>\n",
       "      <td>15.24980</td>\n",
       "      <td>4488.22</td>\n",
       "      <td>1.159212e+11</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104620 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date     Open     High      Low    Close     Volume  \\\n",
       "418481  2022-01-09 20:55:00  3934000  3934000  3931000  3933000   7.091395   \n",
       "418482  2022-01-09 20:56:00  3933000  3935000  3931000  3932000  14.144101   \n",
       "418483  2022-01-09 20:57:00  3932000  3934000  3930000  3933000  19.051929   \n",
       "418484  2022-01-09 20:58:00  3933000  3935000  3930000  3935000  11.908381   \n",
       "418485  2022-01-09 20:59:00  3935000  3936000  3934000  3935000   7.690722   \n",
       "...                     ...      ...      ...      ...      ...        ...   \n",
       "523096  2022-03-23 15:15:00  3666000  3667000  3665000  3665000  39.688187   \n",
       "523097  2022-03-23 15:16:00  3666000  3669000  3665000  3668000  76.731647   \n",
       "523098  2022-03-23 15:17:00  3668000  3671000  3667000  3669000  96.039465   \n",
       "523099  2022-03-23 15:18:00  3667000  3674000  3663000  3663000  91.949217   \n",
       "523100  2022-03-23 15:19:00  3663000  3663000  3660000  3662000  29.505753   \n",
       "\n",
       "         BTC_close     DXY       BTCD  Kimchi_premium   S&P500  Ethereum DeFi  \\\n",
       "418481  52343000.0  95.739  40.435605       -12.94548  4677.04   1.401528e+11   \n",
       "418482  52315000.0  95.739  40.435605       -12.94548  4677.04   1.401528e+11   \n",
       "418483  52313000.0  95.739  40.435605       -12.94548  4677.04   1.401528e+11   \n",
       "418484  52313000.0  95.739  40.435605       -12.94548  4677.04   1.401528e+11   \n",
       "418485  52292000.0  95.739  40.435605       -12.94548  4677.04   1.401528e+11   \n",
       "...            ...     ...        ...             ...      ...            ...   \n",
       "523096  51801000.0  98.793  42.584513        15.24980  4488.22   1.159212e+11   \n",
       "523097  51753000.0  98.793  42.584513        15.24980  4488.22   1.159212e+11   \n",
       "523098  51782000.0  98.793  42.584513        15.24980  4488.22   1.159212e+11   \n",
       "523099  51780000.0  98.793  42.584513        15.24980  4488.22   1.159212e+11   \n",
       "523100  51728000.0  98.793  42.584513        15.24980  4488.22   1.159212e+11   \n",
       "\n",
       "        News_freq  signal  \n",
       "418481       26.0     1.0  \n",
       "418482       26.0     1.0  \n",
       "418483       26.0     1.0  \n",
       "418484       26.0     1.0  \n",
       "418485       26.0     1.0  \n",
       "...           ...     ...  \n",
       "523096       57.0     2.0  \n",
       "523097       57.0     2.0  \n",
       "523098       57.0     2.0  \n",
       "523099       57.0     2.0  \n",
       "523100       57.0     2.0  \n",
       "\n",
       "[104620 rows x 14 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7c0be8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418481, 14)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0616f33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e7d0b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgyeongmocho\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\r\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1562361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import f1_score,precision_recall\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9af468da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    " \n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    \n",
    "    loss_list = []\n",
    "    for idx, (feature, label) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(feature.to(device))\n",
    "        loss = criterion(predicted_label, label.to(device))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        \n",
    "        total_count += label.size(0)\n",
    "        loss_list.append(loss.item())\n",
    "        \n",
    "        if idx+1 % len(feature) == 0 and idx > 0:\n",
    "            accuracy = total_acc/total_count\n",
    "            loss_hist = np.mean(loss_list)\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f'| epoch {epoch} | {idx}/{len(dataloader)} batches '\n",
    "                f'| accuracy {accuracy} | loss {loss_hist}')\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "    wandb.log({'train_loss':np.mean(loss_list),'train_acc':total_acc/total_count})  \n",
    "    return  total_acc/total_count,np.mean(loss_list)\n",
    "    \n",
    "            \n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "    loss_list = []\n",
    "    \n",
    "    score,precision,recall = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (feature, label) in enumerate(dataloader):\n",
    "            feature, label = feature.to(device),label.to(device)\n",
    "            predicted_label = model(feature.to(device))\n",
    "            loss = criterion(predicted_label, label.to(device))\n",
    "            \n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "            loss_list.append(loss.item())\n",
    "            \n",
    "            \n",
    "            \n",
    "            score += f1_score(predicted_label.argmax(1).to(device), label,num_classes=3)\n",
    "            precision += precision_recall(predicted_label.argmax(1).to(device), label, average='macro', num_classes=3)[0]\n",
    "            recall += precision_recall(predicted_label.argmax(1).to(device), label, average='macro', num_classes=3)[1]\n",
    "      \n",
    "        \n",
    "        score = score / len(loss_list)\n",
    "        precision = precision / len(loss_list)\n",
    "        recall = recall / len(loss_list)\n",
    "            \n",
    "    wandb.log({'val_loss':np.mean(loss_list), 'val_acc':total_acc/total_count,'f1_score':score,\n",
    "              'precision':precision,'recall':recall})\n",
    "    \n",
    "    return total_acc/total_count, np.mean(loss_list),score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0a732a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"주어진 patience 이후로 validation loss가 개선되지 않으면 학습을 조기 중지\"\"\"\n",
    "    def __init__(self,path, patience=10, verbose=False, delta=0,):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): validation loss가 개선된 후 기다리는 기간\n",
    "                            Default: 7\n",
    "            verbose (bool): True일 경우 각 validation loss의 개선 사항 메세지 출력\n",
    "                            Default: False\n",
    "            delta (float): 개선되었다고 인정되는 monitered quantity의 최소 변화\n",
    "                            Default: 0\n",
    "            path (str): checkpoint저장 경로\n",
    "                            Default: 'checkpoint.pt'\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        \n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''validation loss가 감소하면 모델을 저장한다.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d01e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd65a4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockingTimeSeriesSplit():\n",
    "    def __init__(self, n_splits):\n",
    "        self.n_splits = n_splits\n",
    "    \n",
    "    def get_n_splits(self, groups):\n",
    "        return self.n_splits\n",
    "    \n",
    "    def split(self, X, y=None, groups=None):\n",
    "        n_samples = len(X)\n",
    "        k_fold_size = n_samples // self.n_splits\n",
    "        indices = np.arange(n_samples)\n",
    "    \n",
    "        margin = 0\n",
    "        for i in range(self.n_splits):\n",
    "            start = i * k_fold_size\n",
    "            stop = start + k_fold_size\n",
    "            mid = int(0.9 * (stop - start)) + start\n",
    "            yield indices[start: mid], indices[mid + margin: stop]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c632767",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__() # 상속한 nn.Module에서 RNN에 해당하는 init 실행\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x): \n",
    "        # input x : (BATCH, LENGTH, INPUT_SIZE) \n",
    "        # 최초의 hidden state와 cell state를 초기화\n",
    "        # 만약 Bi-directional LSTM이라면 아래의 hidden and cell states의 첫번째 차원은 2*self.num_layers \n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) # (BATCH SIZE, SEQ_LENGTH, HIDDEN_SIZE)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)  # hidden state와 동일\n",
    "\n",
    "        # LSTM 순전파\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0)) # out : (BATCH_SIZE, SEQ_LENGTH, HIDDEN_SIZE)  , hn이 lstm의 마지막 hidden state\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 마지막 time step(sequence length)의 hidden state를 사용해 Class들의 logit을 반환합니다(hidden_size -> num_classes). \n",
    "        \n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6aa7d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "input_size = 12\n",
    "hidden_size =10\n",
    "num_layers = 1\n",
    "num_classes = 3\n",
    "\n",
    "lr = 0.0001\n",
    "#base > hidden = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b23e1697",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgyeongmocho\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jbj4278/wandb/run-20220607_023044-hdg43eci</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/gyeongmocho/real/runs/hdg43eci\" target=\"_blank\">lstm_hidden4x_smallbatch</a></strong> to <a href=\"https://wandb.ai/gyeongmocho/real\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "RNN(\n",
      "  (lstm): LSTM(12, 10, batch_first=True)\n",
      "  (fc): Linear(in_features=10, out_features=3, bias=True)\n",
      ")\n",
      "train_feature:torch.Size([75316, 10, 12]),val_feature:torch.Size([8360, 10, 12])\n",
      "0.0001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 1 | time: 6.963653564453125s | valid accuracy 0.2900717703349282 | valid loss 1.1264918178092433\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (inf --> 1.126492).  Saving model ...\n",
      "0.0001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 2 | time: 6.818837404251099s | valid accuracy 0.2909090909090909 | valid loss 1.1328551746506728\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 10\n",
      "0.0001\n",
      "Adjusting learning rate of group 0 to 9.9975e-05.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 3 | time: 6.8296799659729s | valid accuracy 0.2794258373205742 | valid loss 1.1394547028395965\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 2 out of 10\n",
      "9.997532801828658e-05\n",
      "Adjusting learning rate of group 0 to 9.9901e-05.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 4 | time: 6.787309169769287s | valid accuracy 0.26291866028708133 | valid loss 1.1462497624732155\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 3 out of 10\n",
      "9.990133642141359e-05\n",
      "Adjusting learning rate of group 0 to 9.9778e-05.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 5 | time: 6.830119848251343s | valid accuracy 0.2549043062200957 | valid loss 1.1532001784284607\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 4 out of 10\n",
      "9.977809823015401e-05\n",
      "Adjusting learning rate of group 0 to 9.9606e-05.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 6 | time: 6.902909278869629s | valid accuracy 0.24485645933014355 | valid loss 1.1602675038894623\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 5 out of 10\n",
      "9.960573506572391e-05\n",
      "Adjusting learning rate of group 0 to 9.9384e-05.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 7 | time: 6.748271465301514s | valid accuracy 0.2598086124401914 | valid loss 1.1674155037821705\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 6 out of 10\n",
      "9.93844170297569e-05\n",
      "Adjusting learning rate of group 0 to 9.9114e-05.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 8 | time: 6.806991100311279s | valid accuracy 0.25322966507177036 | valid loss 1.1746108261228518\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 7 out of 10\n",
      "9.911436253643445e-05\n",
      "Adjusting learning rate of group 0 to 9.8796e-05.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 9 | time: 6.753680467605591s | valid accuracy 0.2361244019138756 | valid loss 1.1818224962886053\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 8 out of 10\n",
      "9.879583809693738e-05\n",
      "Adjusting learning rate of group 0 to 9.8429e-05.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 10 | time: 6.835935354232788s | valid accuracy 0.23217703349282295 | valid loss 1.1890222644077912\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 9 out of 10\n",
      "9.842915805643157e-05\n",
      "Adjusting learning rate of group 0 to 9.8015e-05.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 11 | time: 6.777920722961426s | valid accuracy 0.23205741626794257 | valid loss 1.1961842677520431\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "save score\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'soft_voting' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-690d3617c846>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mscore_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"save score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mvoting_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoft_voting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mvoting_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoting_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"save voting prob\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'soft_voting' is not defined"
     ]
    }
   ],
   "source": [
    "btss = BlockingTimeSeriesSplit(n_splits=5)\n",
    "n_epochs = 100\n",
    "scale_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'BTC_close', 'DXY', 'BTCD',\n",
    "       'Kimchi_premium', 'S&P500', 'Ethereum DeFi', 'News_freq']\n",
    "score_list = []\n",
    "val_loss_list = []\n",
    "voting_list = []\n",
    "#cross validation\n",
    "\n",
    "wandb.init(project='real', entity='gyeongmoCho',name='lstm_hidden4x_smallbatch')\n",
    "#wandb.watch(model, criterion, log = \"all\" )\n",
    "\n",
    "\n",
    "for idx,(tr_idx, val_idx) in enumerate(btss.split(tr_set)):\n",
    "    \n",
    "    train_data, val_data = tr_set.iloc[tr_idx], tr_set.iloc[val_idx]\n",
    "    \n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_data[scale_cols])#for문을 돌면서 각 train, val을 스케일링ㅇ\n",
    "    train_feature = scaler.transform(train_data[scale_cols])\n",
    "    train_feature = pd.DataFrame(train_feature)                                 \n",
    "    val_feature = scaler.transform(val_data[scale_cols])\n",
    "    val_feature = pd.DataFrame(val_feature)   \n",
    "\n",
    "    \n",
    "    train_feature, train_label = make_dataset(train_feature, train_data['signal'], window_size)\n",
    "    val_feature, val_label = make_dataset(val_feature, val_data['signal'], window_size)\n",
    "\n",
    "    \n",
    "    #모델 선언 \n",
    "    \n",
    "    model = RNN(input_size,hidden_size, num_layers,num_classes).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=0,verbose=True)\n",
    "    total_accu = None\n",
    "\n",
    "\n",
    "    print(model)\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience = 10, verbose = True)\n",
    "\n",
    "\n",
    "\n",
    "    #스케일링된 데이터를 torch Tensor로 변경\n",
    "    val_feature = torch.FloatTensor(val_feature).to(device)\n",
    "    val_label = torch.LongTensor(val_label).to(device)\n",
    "    train_feature = torch.FloatTensor(train_feature).to(device)\n",
    "    train_label  = torch.LongTensor(train_label).to(device)\n",
    "\n",
    "    train_set = TensorDataset(train_feature,train_label)\n",
    "    val_set = TensorDataset(val_feature,val_label)\n",
    "    \n",
    "    #데이터로더 사용\n",
    "    BATCH_SIZE = 32\n",
    "    train_dataloader = DataLoader(train_set , batch_size=BATCH_SIZE,shuffle=False)\n",
    "    valid_dataloader = DataLoader(val_set, batch_size=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "    print(f\"train_feature:{train_feature.shape},val_feature:{val_feature.shape}\" )\n",
    "    \n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        # 현재 learning rate 출력\n",
    "        print(optimizer.param_groups[0]['lr'])\n",
    "        epoch_start_time = time.time()\n",
    "        accu_train, train_loss = train(train_dataloader)\n",
    "        accu_val,val_loss,score = evaluate(valid_dataloader)\n",
    "        if total_accu is not None and total_accu > accu_val:\n",
    "            scheduler.step()\n",
    "        else:\n",
    "            total_accu = accu_val\n",
    "        print('-' * 59)\n",
    "        print(f'| end of epoch {epoch} | time: {time.time()- epoch_start_time}s | '\n",
    "            f'valid accuracy {accu_val} | valid loss {val_loss}'\n",
    "            ) \n",
    "\n",
    "        print('-' * 59)\n",
    "        \n",
    "        early_stopping(val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "    score_list.append(score)\n",
    "    print(\"save score\")\n",
    "    voting_prob = soft_voting(valid_dataloader)\n",
    "    voting_list.append(voting_prob)\n",
    "    print(\"save voting prob\")\n",
    "    \n",
    "    PATH = f\"/home/jbj4278/ETH_data/lstm_hidden4x_smallbatch{idx}.pt\"\n",
    "    torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "\n",
    "\n",
    "                }, PATH)\n",
    "    print('-' * 59)\n",
    "    print('Fold Finish')\n",
    "    print('-' * 59)\n",
    "\n",
    "score_list = list(map(float, score_list))\n",
    "final_f1_score = np.mean(score_list)\n",
    "print(final_f1_score)\n",
    "wandb.log({'mean_f1_score':final_f1_score})\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99de80e0",
   "metadata": {},
   "source": [
    "## f1-score의 fold별 평균이 가장 좋았던 모델\n",
    "### hidden state = 10 , batch = 32, lr = 0.0001, mean_f1score = 0.394"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b487733",
   "metadata": {},
   "source": [
    "#### test_set dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9bac3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'BTC_close', 'DXY', 'BTCD',\n",
    "       'Kimchi_premium', 'S&P500', 'Ethereum DeFi', 'News_freq']\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(tr_set[scale_cols])#for문을 돌면서 각 train, val을 스케일링\n",
    "tr_feature = scaler.transform(tr_set[scale_cols])\n",
    "tr_feature = pd.DataFrame(tr_feature)                                 \n",
    "test_feature = scaler.transform(test_set[scale_cols])\n",
    "test_feature = pd.DataFrame(test_feature)   \n",
    "\n",
    "\n",
    "test_feature, test_label = make_dataset(test_feature, test_set['signal'], window_size)\n",
    "\n",
    "\n",
    "#스케일링된 데이터를 torch Tensor로 변경\n",
    "test_feature = torch.FloatTensor(test_feature).to(device)\n",
    "test_label  = torch.LongTensor(test_label).to(device)\n",
    "\n",
    "final_test_set = TensorDataset(test_feature,test_label)\n",
    "\n",
    "\n",
    "#데이터로더 사용\n",
    "BATCH_SIZE = 32\n",
    "test_dataloader = DataLoader(final_test_set , batch_size=BATCH_SIZE,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6276741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "scale_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'BTC_close', 'DXY', 'BTCD',\n",
    "       'Kimchi_premium', 'S&P500', 'Ethereum DeFi', 'News_freq']\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(tr_set[scale_cols])#for문을 돌면서 각 train, val을 스케일링ㅇ\n",
    "train_feature = scaler.transform(tr_set[scale_cols])\n",
    "train_feature = pd.DataFrame(train_feature)                                 \n",
    " \n",
    "\n",
    "    \n",
    "train_feature, train_label = make_dataset(train_feature, tr_set['signal'], window_size)\n",
    "  \n",
    "\n",
    "train_feature = torch.FloatTensor(train_feature).to(device)\n",
    "train_label  = torch.LongTensor(train_label).to(device)\n",
    "\n",
    "train_set = TensorDataset(train_feature,train_label)\n",
    "\n",
    "\n",
    "#데이터로더 사용\n",
    "BATCH_SIZE = 32\n",
    "final_dataloader = DataLoader(train_set , batch_size=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fe76a7",
   "metadata": {},
   "source": [
    "#### train_set dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7af45683",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "scale_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'BTC_close', 'DXY', 'BTCD',\n",
    "       'Kimchi_premium', 'S&P500', 'Ethereum DeFi', 'News_freq']\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(tr_set[scale_cols])#for문을 돌면서 각 train, val을 스케일링ㅇ\n",
    "train_feature = scaler.transform(tr_set[scale_cols])\n",
    "train_feature = pd.DataFrame(train_feature)                                 \n",
    " \n",
    "\n",
    "    \n",
    "train_feature, train_label = make_dataset(train_feature, tr_set['signal'], window_size)\n",
    "  \n",
    "\n",
    "train_feature = torch.FloatTensor(train_feature).to(device)\n",
    "train_label  = torch.LongTensor(train_label).to(device)\n",
    "\n",
    "train_set = TensorDataset(train_feature,train_label)\n",
    "\n",
    "\n",
    "#데이터로더 사용\n",
    "BATCH_SIZE = 32\n",
    "final_dataloader = DataLoader(train_set , batch_size=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8de38c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"/home/jbj4278/ETH_data/lstm_final_model.pt\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c194948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    }
   ],
   "source": [
    "model = RNN(input_size,hidden_size, num_layers,num_classes).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=0,verbose=True)\n",
    "total_accu = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "496d7b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    " \n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    \n",
    "    loss_list = []\n",
    "    for idx, (feature, label) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(feature.to(device))\n",
    "        loss = criterion(predicted_label, label.to(device))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        \n",
    "        total_count += label.size(0)\n",
    "        loss_list.append(loss.item())\n",
    "        \n",
    "        if idx+1 % len(feature) == 0 and idx > 0:\n",
    "            accuracy = total_acc/total_count\n",
    "            loss_hist = np.mean(loss_list)\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f'| epoch {epoch} | {idx}/{len(dataloader)} batches '\n",
    "                f'| accuracy {accuracy} | loss {loss_hist}')\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "      \n",
    "    return  total_acc/total_count,np.mean(loss_list)\n",
    "    \n",
    "            \n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "    loss_list = []\n",
    "    pred_label = []\n",
    "    pred_prob = []\n",
    "    score,precision,recall = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (feature, label) in enumerate(dataloader):\n",
    "            feature, label = feature.to(device),label.to(device)\n",
    "            predicted_label = model(feature.to(device))\n",
    "            loss = criterion(predicted_label, label.to(device))\n",
    "            \n",
    "            \n",
    "            sm = nn.Softmax(dim=1)\n",
    "            probabilities = sm(predicted_label)\n",
    "            prob_arr = (probabilities.detach().cpu().numpy())[0]\n",
    "            pred_prob.append(prob_arr)\n",
    "            \n",
    "            \n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "            loss_list.append(loss.item())\n",
    "            pred_label.append(predicted_label.argmax(1))\n",
    "            \n",
    "            \n",
    "            score += f1_score(predicted_label.argmax(1).to(device), label,num_classes=3)\n",
    "            precision += precision_recall(predicted_label.argmax(1).to(device), label, average='macro', num_classes=3)[0]\n",
    "            recall += precision_recall(predicted_label.argmax(1).to(device), label, average='macro', num_classes=3)[1]\n",
    "      \n",
    "        \n",
    "        score = score / len(loss_list)\n",
    "        precision = precision / len(loss_list)\n",
    "        recall = recall / len(loss_list)\n",
    "            \n",
    "    \n",
    "    \n",
    "    return total_acc/total_count, np.mean(loss_list),score,pred_label,pred_prob\n",
    "\n",
    "\n",
    "            \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61cb867",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3bef091f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 1 | time: 46.10622835159302s | valid accuracy 0.3188509702705286 | valid loss 1.110277453675547\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (inf --> 1.110277).  Saving model ...\n",
      "0.0001\n",
      "Adjusting learning rate of group 0 to 9.9975e-05.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 2 | time: 45.79668116569519s | valid accuracy 0.31126087372144157 | valid loss 1.1025453397804807\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.110277 --> 1.102545).  Saving model ...\n",
      "9.997532801828658e-05\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 3 | time: 45.56765961647034s | valid accuracy 0.3292515055921996 | valid loss 1.0987710310778487\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.102545 --> 1.098771).  Saving model ...\n",
      "9.997532801828658e-05\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 4 | time: 46.0825674533844s | valid accuracy 0.3664468024089475 | valid loss 1.097194975669231\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.098771 --> 1.097195).  Saving model ...\n",
      "9.997532801828658e-05\n",
      "Adjusting learning rate of group 0 to 9.9901e-05.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 5 | time: 45.70359492301941s | valid accuracy 0.3488958990536278 | valid loss 1.0967555110607672\n",
      "-----------------------------------------------------------\n",
      "Validation loss decreased (1.097195 --> 1.096756).  Saving model ...\n",
      "9.990133642141359e-05\n",
      "Adjusting learning rate of group 0 to 9.9778e-05.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 6 | time: 45.69529747962952s | valid accuracy 0.3509989484752892 | valid loss 1.0968443021679508\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 3\n",
      "9.977809823015401e-05\n",
      "Adjusting learning rate of group 0 to 9.9606e-05.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 7 | time: 45.582310914993286s | valid accuracy 0.3505974572220629 | valid loss 1.0971308227708216\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 2 out of 3\n",
      "9.960573506572391e-05\n",
      "Adjusting learning rate of group 0 to 9.9384e-05.\n",
      "-----------------------------------------------------------\n",
      "| end of epoch 8 | time: 45.669140100479126s | valid accuracy 0.35117101615524327 | valid loss 1.0974469276925476\n",
      "-----------------------------------------------------------\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "tensor(0.3511, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "early_stopping = EarlyStopping(path,patience = 3, verbose = True)\n",
    "\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    # 현재 learning rate 출력\n",
    "    print(optimizer.param_groups[0]['lr'])\n",
    "    epoch_start_time = time.time()\n",
    "    accu_train, train_loss = train(final_dataloader)\n",
    "    accu_test,test_loss,score,label,prob = evaluate(test_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_test:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        total_accu = accu_test\n",
    "    print('-' * 59)\n",
    "    print(f'| end of epoch {epoch} | time: {time.time()- epoch_start_time}s | '\n",
    "        f'valid accuracy {accu_test} | valid loss {test_loss}'\n",
    "        ) \n",
    "\n",
    "    print('-' * 59)\n",
    "\n",
    "    early_stopping(test_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "print(score)\n",
    "torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "\n",
    "\n",
    "                }, path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a42141b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgyeongmocho\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jbj4278/wandb/run-20220607_064227-1tzgkhwd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/gyeongmocho/result/runs/1tzgkhwd\" target=\"_blank\">lstm</a></strong> to <a href=\"https://wandb.ai/gyeongmocho/result\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project='result', entity='gyeongmoCho',name='lstm')\n",
    "wandb.log({'final_f1_score':score})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c1766c",
   "metadata": {},
   "source": [
    "### 예측 라벨 붙여주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7cd0eb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = list(map(list, label))\n",
    "\n",
    "answer = sum(pred_label, [])\n",
    "\n",
    "final_label = []\n",
    "for i in answer:\n",
    "    final_label.append(i.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fb7839",
   "metadata": {},
   "source": [
    "#### voting을 위한 확률값 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "889c13db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_result(model,test_dataloader):\n",
    "    model.eval()\n",
    "    pred_soft = []\n",
    "    pred_hard=[]\n",
    "    \n",
    "    correct_count, all_count = 0,0\n",
    "    with torch.no_grad():\n",
    "        for idx, (feature, label) in enumerate(test_dataloader):\n",
    "            if torch.cuda.is_available():\n",
    "                feature, labels = feature.to(device),label.to(device)\n",
    "            for i in range(len(labels)):\n",
    "                #soft\n",
    "                predicted_label = model(feature.to(device))\n",
    "                sm = nn.Softmax(dim=1)\n",
    "                probabilities = sm(predicted_label)\n",
    "                prob_arr = (probabilities.detach().cpu().numpy())[0]\n",
    "                pred_soft.append(prob_arr)\n",
    "                #hard\n",
    "                logps = model(feature.to(device))\n",
    "                ps = torch.exp(logps)\n",
    "                probab = list(ps.cpu()[0])\n",
    "                pred_label = probab.index(max(probab))\n",
    "                true_label = labels.cpu()[i]\n",
    "                pred_hard.append(pred_label)\n",
    "                if(true_label == pred_label):\n",
    "                    correct_count += 1\n",
    "                all_count += 1\n",
    "                \n",
    "                \n",
    "    return pred_soft ,pred_hard\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e6a2811",
   "metadata": {},
   "outputs": [],
   "source": [
    "soft, hard = make_result(model,test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "79a93074",
   "metadata": {},
   "outputs": [],
   "source": [
    "soft = pd.DataFrame(soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d4bc81df",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_labels = pd.DataFrame(final_label,columns = ['pred_labels'])\n",
    "\n",
    "test_set = test_set[:-10]\n",
    "\n",
    "index = final_labels.index\n",
    "\n",
    "test_set.index = index\n",
    "\n",
    "plus_label_df = test_set.join(final_labels['pred_labels'],how='right') \n",
    "\n",
    "plus_label_df = plus_label_df.join(soft,how='right') \n",
    "\n",
    "plus_label_df.to_csv('final_Lstm_label.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1252fd5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>BTC_close</th>\n",
       "      <th>DXY</th>\n",
       "      <th>BTCD</th>\n",
       "      <th>Kimchi_premium</th>\n",
       "      <th>S&amp;P500</th>\n",
       "      <th>Ethereum DeFi</th>\n",
       "      <th>News_freq</th>\n",
       "      <th>signal</th>\n",
       "      <th>pred_labels</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-09 20:55:00</td>\n",
       "      <td>3934000</td>\n",
       "      <td>3934000</td>\n",
       "      <td>3931000</td>\n",
       "      <td>3933000</td>\n",
       "      <td>7.091395</td>\n",
       "      <td>52343000.0</td>\n",
       "      <td>95.739</td>\n",
       "      <td>40.435605</td>\n",
       "      <td>-12.94548</td>\n",
       "      <td>4677.04</td>\n",
       "      <td>1.401528e+11</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.372456</td>\n",
       "      <td>0.330337</td>\n",
       "      <td>0.297207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-09 20:56:00</td>\n",
       "      <td>3933000</td>\n",
       "      <td>3935000</td>\n",
       "      <td>3931000</td>\n",
       "      <td>3932000</td>\n",
       "      <td>14.144101</td>\n",
       "      <td>52315000.0</td>\n",
       "      <td>95.739</td>\n",
       "      <td>40.435605</td>\n",
       "      <td>-12.94548</td>\n",
       "      <td>4677.04</td>\n",
       "      <td>1.401528e+11</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.372456</td>\n",
       "      <td>0.330337</td>\n",
       "      <td>0.297207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-09 20:57:00</td>\n",
       "      <td>3932000</td>\n",
       "      <td>3934000</td>\n",
       "      <td>3930000</td>\n",
       "      <td>3933000</td>\n",
       "      <td>19.051929</td>\n",
       "      <td>52313000.0</td>\n",
       "      <td>95.739</td>\n",
       "      <td>40.435605</td>\n",
       "      <td>-12.94548</td>\n",
       "      <td>4677.04</td>\n",
       "      <td>1.401528e+11</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.372456</td>\n",
       "      <td>0.330337</td>\n",
       "      <td>0.297207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-09 20:58:00</td>\n",
       "      <td>3933000</td>\n",
       "      <td>3935000</td>\n",
       "      <td>3930000</td>\n",
       "      <td>3935000</td>\n",
       "      <td>11.908381</td>\n",
       "      <td>52313000.0</td>\n",
       "      <td>95.739</td>\n",
       "      <td>40.435605</td>\n",
       "      <td>-12.94548</td>\n",
       "      <td>4677.04</td>\n",
       "      <td>1.401528e+11</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.372456</td>\n",
       "      <td>0.330337</td>\n",
       "      <td>0.297207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-09 20:59:00</td>\n",
       "      <td>3935000</td>\n",
       "      <td>3936000</td>\n",
       "      <td>3934000</td>\n",
       "      <td>3935000</td>\n",
       "      <td>7.690722</td>\n",
       "      <td>52292000.0</td>\n",
       "      <td>95.739</td>\n",
       "      <td>40.435605</td>\n",
       "      <td>-12.94548</td>\n",
       "      <td>4677.04</td>\n",
       "      <td>1.401528e+11</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.372456</td>\n",
       "      <td>0.330337</td>\n",
       "      <td>0.297207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104605</th>\n",
       "      <td>2022-03-23 15:05:00</td>\n",
       "      <td>3662000</td>\n",
       "      <td>3664000</td>\n",
       "      <td>3660000</td>\n",
       "      <td>3662000</td>\n",
       "      <td>29.579468</td>\n",
       "      <td>51697000.0</td>\n",
       "      <td>98.793</td>\n",
       "      <td>42.584513</td>\n",
       "      <td>15.24980</td>\n",
       "      <td>4488.22</td>\n",
       "      <td>1.159212e+11</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.369807</td>\n",
       "      <td>0.298835</td>\n",
       "      <td>0.331358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104606</th>\n",
       "      <td>2022-03-23 15:06:00</td>\n",
       "      <td>3662000</td>\n",
       "      <td>3666000</td>\n",
       "      <td>3661000</td>\n",
       "      <td>3664000</td>\n",
       "      <td>31.708145</td>\n",
       "      <td>51710000.0</td>\n",
       "      <td>98.793</td>\n",
       "      <td>42.584513</td>\n",
       "      <td>15.24980</td>\n",
       "      <td>4488.22</td>\n",
       "      <td>1.159212e+11</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.369807</td>\n",
       "      <td>0.298835</td>\n",
       "      <td>0.331358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104607</th>\n",
       "      <td>2022-03-23 15:07:00</td>\n",
       "      <td>3665000</td>\n",
       "      <td>3669000</td>\n",
       "      <td>3664000</td>\n",
       "      <td>3666000</td>\n",
       "      <td>42.205886</td>\n",
       "      <td>51745000.0</td>\n",
       "      <td>98.793</td>\n",
       "      <td>42.584513</td>\n",
       "      <td>15.24980</td>\n",
       "      <td>4488.22</td>\n",
       "      <td>1.159212e+11</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.369807</td>\n",
       "      <td>0.298835</td>\n",
       "      <td>0.331358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104608</th>\n",
       "      <td>2022-03-23 15:08:00</td>\n",
       "      <td>3664000</td>\n",
       "      <td>3666000</td>\n",
       "      <td>3663000</td>\n",
       "      <td>3665000</td>\n",
       "      <td>20.221637</td>\n",
       "      <td>51731000.0</td>\n",
       "      <td>98.793</td>\n",
       "      <td>42.584513</td>\n",
       "      <td>15.24980</td>\n",
       "      <td>4488.22</td>\n",
       "      <td>1.159212e+11</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.373138</td>\n",
       "      <td>0.302516</td>\n",
       "      <td>0.324346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104609</th>\n",
       "      <td>2022-03-23 15:09:00</td>\n",
       "      <td>3666000</td>\n",
       "      <td>3666000</td>\n",
       "      <td>3664000</td>\n",
       "      <td>3664000</td>\n",
       "      <td>34.800540</td>\n",
       "      <td>51744000.0</td>\n",
       "      <td>98.793</td>\n",
       "      <td>42.584513</td>\n",
       "      <td>15.24980</td>\n",
       "      <td>4488.22</td>\n",
       "      <td>1.159212e+11</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.373138</td>\n",
       "      <td>0.302516</td>\n",
       "      <td>0.324346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104610 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date     Open     High      Low    Close     Volume  \\\n",
       "0       2022-01-09 20:55:00  3934000  3934000  3931000  3933000   7.091395   \n",
       "1       2022-01-09 20:56:00  3933000  3935000  3931000  3932000  14.144101   \n",
       "2       2022-01-09 20:57:00  3932000  3934000  3930000  3933000  19.051929   \n",
       "3       2022-01-09 20:58:00  3933000  3935000  3930000  3935000  11.908381   \n",
       "4       2022-01-09 20:59:00  3935000  3936000  3934000  3935000   7.690722   \n",
       "...                     ...      ...      ...      ...      ...        ...   \n",
       "104605  2022-03-23 15:05:00  3662000  3664000  3660000  3662000  29.579468   \n",
       "104606  2022-03-23 15:06:00  3662000  3666000  3661000  3664000  31.708145   \n",
       "104607  2022-03-23 15:07:00  3665000  3669000  3664000  3666000  42.205886   \n",
       "104608  2022-03-23 15:08:00  3664000  3666000  3663000  3665000  20.221637   \n",
       "104609  2022-03-23 15:09:00  3666000  3666000  3664000  3664000  34.800540   \n",
       "\n",
       "         BTC_close     DXY       BTCD  Kimchi_premium   S&P500  Ethereum DeFi  \\\n",
       "0       52343000.0  95.739  40.435605       -12.94548  4677.04   1.401528e+11   \n",
       "1       52315000.0  95.739  40.435605       -12.94548  4677.04   1.401528e+11   \n",
       "2       52313000.0  95.739  40.435605       -12.94548  4677.04   1.401528e+11   \n",
       "3       52313000.0  95.739  40.435605       -12.94548  4677.04   1.401528e+11   \n",
       "4       52292000.0  95.739  40.435605       -12.94548  4677.04   1.401528e+11   \n",
       "...            ...     ...        ...             ...      ...            ...   \n",
       "104605  51697000.0  98.793  42.584513        15.24980  4488.22   1.159212e+11   \n",
       "104606  51710000.0  98.793  42.584513        15.24980  4488.22   1.159212e+11   \n",
       "104607  51745000.0  98.793  42.584513        15.24980  4488.22   1.159212e+11   \n",
       "104608  51731000.0  98.793  42.584513        15.24980  4488.22   1.159212e+11   \n",
       "104609  51744000.0  98.793  42.584513        15.24980  4488.22   1.159212e+11   \n",
       "\n",
       "        News_freq  signal  pred_labels         0         1         2  \n",
       "0            26.0     1.0            0  0.372456  0.330337  0.297207  \n",
       "1            26.0     1.0            0  0.372456  0.330337  0.297207  \n",
       "2            26.0     1.0            0  0.372456  0.330337  0.297207  \n",
       "3            26.0     1.0            0  0.372456  0.330337  0.297207  \n",
       "4            26.0     1.0            0  0.372456  0.330337  0.297207  \n",
       "...           ...     ...          ...       ...       ...       ...  \n",
       "104605       57.0     2.0            0  0.369807  0.298835  0.331358  \n",
       "104606       57.0     2.0            0  0.369807  0.298835  0.331358  \n",
       "104607       57.0     2.0            0  0.369807  0.298835  0.331358  \n",
       "104608       57.0     2.0            0  0.373138  0.302516  0.324346  \n",
       "104609       57.0     2.0            0  0.373138  0.302516  0.324346  \n",
       "\n",
       "[104610 rows x 18 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plus_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90289a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
